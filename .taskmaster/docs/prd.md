# 제품 요구사항 명세서(PRD): 3GPP Peg 분석 - 자동화된 통계 및 이상 탐지

## 1.0 비전 및 요약

### 1.1 문제 정의

현재 네트워크 성능 엔지니어(Network Performance Engineer, NPE)는 순차적인 테스트 실행에서 생성된 3GPP 성능 이벤트 생성(Performance Event Generation, peg) 데이터를 분석하는 데 상당한 수작업을 투입하고 있습니다. 이 프로세스는 방대한 데이터 로그 내에서 유효한 테스트 구간을 수동으로 찾아내고, 스프레드시트 기반의 통계적 비교를 수행하며, 성능 저하를 식별하기 위해 주관적인 경험에 의존하는 작업을 포함합니다. 이러한 방식은 시간이 많이 소요되고 인적 오류에 취약하며, 근본적인 네트워크 문제를 나타낼 수 있는 미묘하거나 복잡한 비정상 패턴을 탐지할 정교함이 부족합니다.[1] 특히 다수의 사용자 장비(Multi-UE)가 동원되는 테스트 환경에서는 데이터의 편차가 커서 단순 평균 비교만으로는 정확한 성능 평가가 어렵습니다.

### 1.2 제안 솔루션

본 문서는 기존 3GPP peg 분석 프론트엔드에 추가될 새로운 'Statistics' 기능의 명세를 정의합니다. 이 기능은 분석 워크플로우 전반을 자동화하여 엔지니어의 개입을 최소화합니다. 사용자가 간단한 시간 범위를 입력하면, 시스템은 강력한 백엔드 프로세스를 트리거하여 유효 테스트 기간을 자동으로 식별하고, 'n-1' 기간과 'n' 기간 간의 엄격한 통계적 비교를 수행하며, 최첨단 머신러닝 모델을 적용하여 이상 징후를 탐지합니다. 시스템은 분석 결과를 바탕으로 peg 및 셀(cell) 레벨에서 명확한 데이터 기반의 'Pass/Fail' 판정을 내리고, 직관적이고 상호작용이 가능한 대시보드를 통해 결과를 제공합니다. 이를 통해 수 시간에 걸친 수작업 분석을 단 몇 분 만에 완료되는 자동화되고 신뢰성 높은 통찰력 생성 과정으로 전환하고자 합니다.

## 2.0 사용자 페르소나 및 스토리

### 2.1 주요 페르소나: 네트워크 성능 엔지니어(NPE)

*   **역할**: 소프트웨어 업그레이드, 구성 변경 또는 신규 기능 배포 후 네트워크 성능을 검증하는 책임을 집니다.
*   **목표**: 성능 저하를 신속하게 식별하고, 실패의 근본 원인을 이해하며, 경영진 및 개발팀에 명확하고 데이터에 기반한 보고서를 제공합니다. 반복적인 분석 작업에 소요되는 시간을 최소화하고자 합니다.
*   **불만 사항**: 올바른 45분 테스트 윈도우를 찾기 위해 몇 시간 분량의 로그 데이터를 뒤지는 것, 엔지니어마다 분석 결과가 일관되지 않은 것, 특정 조건에서만 나타나는 미묘한 성능 문제를 놓치는 것 등이 있습니다.

### 2.2 사용자 스토리

#### 2.2.1 에픽: 테스트 기간 식별

*   NPE로서, 나는 '2025-08-08 00:00'부터 '2025-08-08 12:00'과 같은 넓은 시간 범위를 입력하면 시스템이 해당 범위 내에서 유효하고 연속적인 모든 테스트 기간을 자동으로 식별하기를 원한다. 이를 통해 로그를 수동으로 스캔할 필요가 없어진다.
*   NPE로서, 나는 시스템이 가장 최근의 유효 테스트 기간 두 개를 자동으로 'n' 및 'n-1' 구간으로 선택하여 비교하기를 원한다. 이를 통해 기본 분석이 항상 가장 관련성 높은 비교가 되도록 한다.
*   NPE로서, 나는 시스템의 자동 선택을 수동으로 변경하고 식별된 테스트 기간 중 임의의 두 기간을 선택하여 비교할 수 있기를 원한다. 이를 통해 과거 데이터 분석이나 특정 목적의 분석을 수행할 수 있다.

#### 2.2.2 에픽: 통계 분석 및 판정

*   NPE로서, 나는 전체적인 Pass/Fail 상태와 실패한 peg/cell의 수를 포함한 분석 요약 정보를 한눈에 보기를 원한다. 이를 통해 테스트 결과를 즉시 파악할 수 있다.
*   NPE로서, 나는 각 peg 및 cell에 대해 'n-1'과 'n' 기간 사이의 핵심 통계 지표(평균 델타, RSD, Z-Score)를 비교하는 상세 테이블을 보기를 원한다. 이를 통해 어떤 특정 구성 요소의 성능이 저하되었는지 식별할 수 있다.
*   NPE로서, 나는 시스템이 Z-Score 및 RSD에 대해 사전 정의된 임계값을 기반으로 peg/cell을 자동으로 'Fail'로 플래그 지정하기를 원한다. 이를 통해 판정이 객관적이고 일관되게 이루어진다.

#### 2.2.3 에픽: 이상 탐지 및 진단

*   NPE로서, 나는 시스템이 각 peg/cell의 시계열 데이터에 대해 LSTM 오토인코더와 같은 고급 이상 탐지 모델을 실행하기를 원한다. 이를 통해 단순한 통계로는 놓칠 수 있는 비정상적인 동작을 식별할 수 있다.
*   NPE로서, 나는 선택한 peg/cell의 시계열 데이터를 'n-1'과 'n' 기간이 중첩된 형태로 시각화하고, 탐지된 모든 이상 징후가 명확하게 강조 표시되기를 원한다. 이를 통해 통계적 성능 저하와 특정 이상 이벤트 간의 관계를 시각적으로 확인할 수 있다.
*   NPE로서, 나는 Transformer와 같은 더 새롭고 진보된 모델을 실행하여 다른 통찰력을 제공하는지 확인할 수 있는 옵션을 원한다. 이를 통해 우리의 분석 역량을 최신 기술 수준으로 유지할 수 있다.

## 3.0 기능 상세: 'Statistics' 모듈

본 섹션에서는 분석 엔진과 사용자 인터페이스 구성 요소의 핵심 로직 및 기능을 상세히 설명합니다.

### 3.1 자동화된 테스트 기간 식별

#### 3.1.1 사용자 인터페이스 및 워크플로우

UI는 날짜/시간 범위 선택기를 특징으로 합니다. 사용자가 범위를 선택하고 "Analyze" 버튼을 클릭하면, 백엔드 프로세스가 비동기적으로 실행되는 동안 로딩 표시기가 나타납니다. 초기 검색이 완료되면, 발견된 유효 테스트 기간 목록(예: "Test Run 1: 01:15-02:00", "Test Run 2: 03:15-04:00")이 "Baseline Period (n-1)"와 "Comparison Period (n)"라는 레이블이 붙은 두 개의 드롭다운 메뉴에 채워지며, 가장 최근의 두 기간이 기본값으로 선택됩니다.

#### 3.1.2 백엔드 알고리즘: 2단계 활성 구간 탐지

이 기능의 핵심은 유효한 테스트 구간을 안정적으로 찾는 알고리즘입니다. 단순한 접근 방식은 실패할 수 있으므로, 2단계 프로세스가 필요합니다.

*   **1단계: 변화점 탐지(Change Point Detection, CPD)를 이용한 대략적인 구간 분할**: 시스템은 사용자가 지정한 범위에 대해 핵심 지표(예: 총 데이터 볼륨 또는 요약 peg 값)의 시계열을 처리합니다. 신호의 통계적 속성이 변하는 지점을 식별하기 위해 강력한 오프라인 CPD 알고리즘을 사용합니다. Python의 `ruptures` 라이브러리에서 제공하는 **PELT(Pruned Exact Linear Time)** 탐색 방법은 정확성과 효율성 측면에서 권장됩니다.[2, 3, 4, 5] 모델은 테스트 기간이 낮거나 없는 활동에서 높고 지속적인 활동으로 전환되는 특징을 가지므로, **평균 및 분산**의 변화를 탐지하도록 구성됩니다.[6, 7]

*   **2단계: 구간 필터링 및 검증**: PELT에 의해 생성된 구간들은 후처리 과정을 거칩니다. 한 구간이 "유효 테스트 기간"으로 간주되려면 다음 모든 기준을 충족해야 합니다.
    *   **최소 지속 시간**: 일시적인 노이즈나 불완전한 테스트를 걸러내기 위해 구간 길이는 설정 가능한 임계값(예: 40분)보다 길어야 합니다.
    *   **지속적인 활동**: 유휴 기간이 아님을 보장하기 위해 구간 내 핵심 지표의 평균값은 특정 임계값 이상이어야 합니다.
    *   **통계적 안정성**: 불안정한 기간이나 테스트 간 전환 구간을 필터링하고, 선택된 기간이 일관된 테스트 상태를 나타내도록 보장하기 위해 구간 *내부* 데이터의 분산은 특정 임계값 미만이어야 합니다.[8, 9]

사용자는 약 45분 동안 "정상적으로 수집된 통계"를 찾기를 원합니다. 표준적인 변화점 탐지 알고리즘은 테스트의 시작, 끝뿐만 아니라 테스트 *중*의 일시적인 네트워크 불안정이나 데이터 중단과 같은 *모든* 통계적 변화를 식별합니다.[5] 단순히 CPD에만 의존하면 거짓 양성을 초래하고 테스트 구간을 잘못 분할할 수 있습니다. 실제 요구사항은 변화점으로 경계가 정해질 뿐만 아니라, 충분한 길이와 내부적 안정성이라는 특정 속성을 나타내는 구간을 찾는 것입니다. 따라서, 2단계 필터링은 사용자의 의도를 충족시키기 위한 필수적인 요구사항이며, 이는 문제를 단순한 "변화 탐지"에서 "안정적이고 활성화된 구간 식별"로 전환시킵니다.

### 3.2 핵심 통계 분석 엔진

#### 3.2.1 지표 정의

각 peg 및 cell에 대해, 백엔드는 'n' 기간과 'n-1' 기간을 비교하여 다음 지표들을 계산합니다. 두 구간의 특정 peg에 대한 데이터 포인트 집합을 각각 $X_{n-1}$과 $X_{n}$이라 할 때, 다음과 같이 정의됩니다.

*   **평균(Average, Avg)**: $\mu = \frac{1}{N}\sum_{i=1}^{N} x_i$
*   **델타(Delta)**: $\Delta\mu = \mu_n - \mu_{n-1}$
*   **표준편차(Standard Deviation, Std Dev)**: $\sigma = \sqrt{\frac{1}{N-1}\sum_{i=1}^{N} (x_i - \mu)^2}$
*   **상대표준편차(Relative Standard Deviation, RSD)**: $RSD = \frac{\sigma_n}{\mu_n}$. 이 지표는 Multi-UE 테스트의 안정성과 일관성을 이해하는 데 중요하며, 높은 분산은 문제를 나타낼 수 있습니다.
*   **Z-점수(Z-Score)**: $Z = \frac{\mu_n - \mu_{n-1}}{\sqrt{\frac{\sigma_{n-1}^2}{N_{n-1}} + \frac{\sigma_n^2}{N_n}}}$. 이 값은 데이터의 변동성을 고려하여 델타를 표준화함으로써, 유의미한 변화를 나타내는 강력하고 정규화된 지표를 제공합니다.

#### 3.2.2 데이터 집계

이러한 계산은 약 12,000개의 모든 peg에 대해 수행됩니다. 약 300개의 요약 peg 그룹에 대해서는 요약 통계(예: 평균 Z-점수, Z-점수가 임계값을 초과하는 peg의 수)가 계산됩니다.

### 3.3 고급 이상 탐지 엔진

#### 3.3.1 Multi-UE 데이터에 대한 피처 엔지니어링

머신러닝 모델에 데이터를 입력하기 전에 중요한 전처리 단계가 필요합니다. 테스트 기간 내 각 타임스탬프에 대해, 특정 peg/cell에 대한 모든 UE의 원시 데이터는 피처 벡터로 집계됩니다. 이 벡터는 해당 순간의 UE 분포 통계를 나타냅니다.

*   **입력 벡터**: `[평균, 표준편차, 분산, 왜도, 첨도, 25백분위수, 50백분위수, 75백분위수]`

네트워크 분석에서 사용되는 피처 추출 기법에서 영감을 받은 이 접근 방식은 [10, 11, 12], 고차원적이고 노이즈가 많은 Multi-UE 문제를 LSTM이나 Transformer와 같은 모델에 이상적인 구조화된 다변량 시계열로 변환합니다.

Multi-UE 테스트의 편차를 고려해야 한다는 요구사항을 충족시키기 위해, 수백 개의 UE 데이터를 각각 별개의 피처로 다루는 것은 극도로 높은 차원의 입력 공간을 생성하여 모델 훈련을 어렵게 하고 차원의 저주에 취약하게 만듭니다.[13] 대신, 각 타임스탬프에서 UE 집단의 *통계적 동작*을 모델링하는 것으로 문제의 관점을 전환해야 합니다. 각 타임스탬프에서 평균, 표준편차, 왜도와 같은 피처를 생성함으로써, 사용자가 우려하는 중심 경향과 편차를 정보가 풍부한 소형 피처 벡터로 직접 인코딩합니다. 이는 후속 LSTM/Transformer 모델의 학습 과제를 다루기 쉽고 문제의 본질에 더 부합하도록 만듭니다.

#### 3.3.2 주요 모델: LSTM 오토인코더

이 모델은 이상 탐지를 위한 기본 모델로 사용됩니다.

*   **아키텍처**: PyTorch 또는 TensorFlow로 구현된 스택형 LSTM 계층을 사용하는 표준 인코더-디코더 아키텍처가 사용됩니다.[7, 14, 15, 16] 인코더는 입력 시퀀스(예: 60개 타임스탬프의 윈도우)를 잠재 벡터로 압축하고, 디코더는 이 벡터로부터 원본 시퀀스를 재구성하려고 시도합니다.
*   **훈련**: 모델은 "정상" 또는 "골든" 테스트 실행으로 알려진 대규모 데이터 코퍼스에 대해 사전 훈련됩니다. 이를 통해 정상 패턴을 낮은 오류로 재구성하는 법을 학습합니다.
*   **이상 점수**: 분석 중에 모델은 'n' 기간의 시계열을 처리합니다. 각 타임스탬프의 이상 점수는 입력과 재구성된 출력 간의 **재구성 오류**(예: 평균 제곱 오차 또는 평균 절대 오차)가 됩니다.[13, 17, 18, 19, 20] 높은 오류는 모델이 해당 패턴에 익숙하지 않음을 나타내며, 잠재적 이상 징후로 플래그 지정됩니다.

#### 3.3.3 최신 기술 강화: Transformer 기반 모델

"최신 기법"을 통합하기 위해 두 번째로 더 진보된 모델이 구현됩니다.

*   **근거**: Transformer 모델은 **셀프 어텐션 메커니즘**을 통해 시계열 데이터 내의 장거리 의존성과 복잡한 변수 간 관계를 LSTM보다 효과적으로 포착할 수 있습니다. LSTM은 매우 긴 시퀀스에서 어려움을 겪을 수 있습니다.[21, 22, 23] 이는 더 긴 시간 윈도우에 걸쳐 나타나는 미묘한 이상 징후를 탐지하는 데 더 나은 성능을 보일 수 있음을 의미합니다.
*   **아키텍처**: Transformer 기반의 재구성 모델(오토인코더 구조와 유사)이 사용됩니다.[24, 21, 25] 셀프 어텐션 계층은 피처 엔지니어링된 다변량 시계열의 복잡한 패턴을 학습합니다.
*   **이상 점수**: LSTM AE와 유사하게, 이상 점수는 재구성 오류를 기반으로 합니다.

#### 3.3.4 앙상블 이상 점수 산정

단일하고 강력한 이상 점수를 제공하기 위해 LSTM과 Transformer 모델의 출력이 결합됩니다.

*   **방법**: 두 모델의 이상 점수(재구성 오류)는 정규화됩니다(예: Min-Max 스케일링을 사용하여 0-1 범위로 변환). 최종적으로 보고되는 이상 점수는 이 정규화된 점수들의 **가중 평균**이 됩니다. 초기에는 50/50의 단순 평균으로 설정할 수 있습니다. 이 앙상블 접근 방식은 단일 모델의 거짓 음성/양성 위험을 줄이고 강건성을 향상시킵니다.[26, 27, 28, 29]

신뢰성 있는 시스템(LSTM 오토인코더)과 "최신 기법"(Transformer)을 모두 원하는 사용자 요구를 충족시키기 위해, 단일 모델에 의존하는 것은 위험합니다. 연구에 따르면 단일 모델이 보편적으로 우수하지는 않습니다. 예를 들어[25]에서는 CNN이 Transformer보다 우수한 성능을 보인 사례가 있습니다. 더 정교하고 강력한 엔지니어링 솔루션은 여러 모델을 활용하는 것입니다. 두 모델을 모두 실행하고 그 점수를 융합함으로써 [28, 30], 특정 단일 모델의 약점에 덜 민감한 시스템을 구축할 수 있습니다. 이는 또한 향후 새로운 모델을 추가하고 앙상블 점수에 통합할 수 있는 모듈식 프레임워크를 생성하여 시스템을 본질적으로 확장 가능하게 만듭니다.

### 3.4 자동화된 판정 및 보고

#### 3.4.1 Pass/Fail 로직 엔진

설정 가능한 규칙 엔진이 각 peg 및 cell의 최종 Pass/Fail 상태를 결정합니다. 다음 조건 중 **하나라도** 충족되면 "Fail"이 트리거됩니다.

*   **Z-점수 임계값**: `abs(Z-Score) > 3.0` (설정 가능)
*   **RSD 임계값**: `RSD > 0.2` (설정 가능, 특정 peg에 따라 값 상이)
*   **이상 점수 임계값**: 'n' 기간의 평균 앙상블 이상 점수가 임계값을 초과하는 경우. 이 임계값은 정상 데이터의 이상 점수 분포로부터 통계적으로 결정됩니다(예: 99번째 백분위수).[7, 31]

#### 3.4.2 결과 시각화 - 메인 대시보드

기본 뷰는 한눈에 이해할 수 있도록 UI/UX 모범 사례를 따릅니다.[32, 33, 34, 35]

*   **요약 카드**: 상단에는 큰 글꼴의 카드로 다음 정보가 표시됩니다.
    *   전체 테스트 상태: "PASS" / "FAIL"
    *   실패한 Pegs: "12 / 289"
    *   실패한 Cells: "45 / 12104"
    *   분석 기간: "n-1: [timestamp] vs n: [timestamp]"
*   **요약 테이블**: 모든 peg/cell을 나열하는 페이지네이션, 정렬 및 필터링이 가능한 테이블입니다. 아래 표 1 명세를 참조하십시오.

#### 3.4.3 결과 시각화 - 상세 뷰

요약 테이블의 행을 클릭하면 해당 peg/cell에 대한 상세 진단 뷰로 이동합니다.

*   **연동된 시각화**: 이 뷰는 분석의 스토리를 전달하기 위해 여러 연동된 구성 요소를 특징으로 합니다.[33, 36]
    1.  **지표 테이블**: Avg, Std Dev, RSD, Z-Score, 이상 점수에 대한 `n-1` 대 `n` 값을 보여주는 간단한 테이블.
    2.  **시계열 비교 차트**: 주요 지표(예: 평균 처리량)를 시간에 따라 플로팅하는 단일 라인 차트(MUI X Charts와 같은 라이브러리 사용 [37]). `n-1` 기간은 회색 선으로, `n` 기간은 파란색 선으로 표시됩니다.
    3.  **이상 징후 강조**: 동일한 차트에서, 'n' 기간 중 앙상블 이상 점수가 임계값을 초과한 모든 시점은 눈에 띄는 빨간색 점이나 음영 처리된 빨간색 영역으로 표시됩니다.[38] 이는 통계적 실패(예: 파란색 선이 회색 선보다 낮음)와 이를 유발한 특정 이상 행동 순간 사이의 즉각적인 시각적 연결을 제공합니다.

---

## 4.0 시스템 아키텍처 및 데이터 흐름

### 4.1 고수준 아키텍처

시스템은 사용자 경험을 저해하지 않으면서 장시간 실행되는 계산 집약적 작업을 처리하도록 설계된 현대적이고 확장 가능한 웹 애플리케이션 스택을 사용하여 설계됩니다.

*   **프론트엔드**: 모든 사용자 상호 작용 및 데이터 시각화를 담당하는 **React** 단일 페이지 애플리케이션(SPA).[39]
*   **백엔드 API**: RESTful API 엔드포인트를 제공하는 **Python FastAPI** 서버. FastAPI는 고성성능과 네이티브 비동기 지원으로 인해 선택되었습니다.[40, 41]
*   **태스크 큐**: **Celery**가 분석 작업의 비동기 실행을 관리합니다. 이는 장시간 실행되는 분석을 API 서버에서 분리하여 요청 시간 초과를 방지하고 더 많은 Celery 워커를 추가하여 시스템을 수평적으로 확장할 수 있게 합니다.[40, 42, 41]
*   **메시지 브로커**: **Redis**는 FastAPI와 Celery 간의 메시지 브로커 역할을 하며, 완료된 작업의 상태와 출력을 저장하는 결과 백엔드로도 사용됩니다.[40, 42, 41]

### 4.2 비동기 데이터 흐름

1.  **시작**: React 클라이언트는 시간 범위와 대상 peg를 포함한 요청을 FastAPI 엔드포인트 `/