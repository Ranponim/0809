{
  "master": {
    "tasks": [
      {
        "id": 55,
        "title": "Finalize Payload Strategy & Document Schema",
        "description": "Make the final decision on the payload strategy (C. Hybrid) and document the detailed MongoDB schema for AnalysisResultModel, including 'analysis_raw_compact' and 'results_overview'.",
        "details": "Confirm the structure and fields for 'analysis_raw_compact' (e.g., top_k_segments, percentiles, notes) and 'results_overview' (e.g., summary, key_findings). This decision is critical for subsequent implementation.",
        "testStrategy": "Review and approve the documented schema by relevant stakeholders.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 56,
        "title": "Define Initial Global Token/Payload Limits",
        "description": "Establish initial values for global limits such as 'max_rows_global', 'max_chars_prompt', 'max_selected_pegs', and 'max_raw_bytes'. These values will serve as configurable parameters.",
        "details": "Consider the MongoDB 16MB document size limit for 'max_raw_bytes' and LLM token limits for prompt-related values. Document these initial settings.",
        "testStrategy": "Documented limits are reviewed and agreed upon by the team.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 57,
        "title": "Update Pydantic Models for New Fields",
        "description": "Modify the Pydantic models, specifically 'AnalysisResultCreate' and 'AnalysisResultModel', in FastAPI to include the new 'results_overview' and 'analysis_raw_compact' fields as optional.",
        "details": "Ensure that Pydantic aliases for camelCase input are maintained for backward compatibility, while enforcing snake_case storage in the database.",
        "testStrategy": "Unit tests for Pydantic model validation and serialization/deserialization with new fields and alias handling.",
        "priority": "high",
        "dependencies": [
          55
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 58,
        "title": "Implement Prompt Token Estimation Utility",
        "description": "Create a utility function, e.g., 'estimate_prompt_tokens(text)', that provides a heuristic estimate of the token count for a given text string. This utility will be used before sending prompts to the LLM.",
        "details": "The estimation can be based on character length or a more sophisticated method if a tokenization library is available for the specific LLM (Google gemini-2.5-flash).",
        "testStrategy": "Unit tests for the utility function with various text lengths and content, verifying estimation accuracy against actual token counts (if possible) or expected heuristics.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 59,
        "title": "Integrate Global Limits into LLM Prompt Generation",
        "description": "Implement logic within 'analysis_llm.py' to apply the defined global limits ('max_rows_global', 'max_chars_prompt', 'max_selected_pegs') during the prompt construction phase.",
        "details": "This involves checking the current prompt size/content against the limits and triggering truncation or sampling mechanisms if thresholds are exceeded.",
        "testStrategy": "Integration tests verifying that prompts exceeding limits are correctly truncated/sampled and that the process is logged.",
        "priority": "high",
        "dependencies": [
          56,
          58
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 60,
        "title": "Develop Token-Aware Chunking for Table Data",
        "description": "Implement a mechanism to summarize or sample large table datasets (e.g., KPI time series, PEG data) to reduce their token footprint when included in the LLM prompt.",
        "details": "Focus on retaining critical information such as summary statistics, representative segments (max/min/outliers), and top-K KPIs/PEGs.",
        "testStrategy": "Unit tests for the chunking logic, ensuring data reduction while preserving key insights. Integration tests with LLM calls to confirm token reduction.",
        "priority": "high",
        "dependencies": [
          59
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 61,
        "title": "Develop Token-Aware Chunking for Chart Base64",
        "description": "Modify the chart generation process to include only the most essential chart (e.g., an overall summary chart) as Base64 directly in the LLM prompt.",
        "details": "For detailed charts, provide links or file paths instead of embedding them directly to minimize token usage. This reduces the number of Base64 images sent to the LLM.",
        "testStrategy": "Verify that only the designated 'overall' chart is embedded and that other charts are referenced by path. Confirm token reduction in LLM calls.",
        "priority": "medium",
        "dependencies": [
          59
        ],
        "status": "cancelled",
        "subtasks": []
      },
      {
        "id": 62,
        "title": "Refine LLM Prompt Templates",
        "description": "Review and optimize existing prompt templates to remove redundant instructions, duplicate metadata, and verbose fixed text sections to minimize overall token usage.",
        "details": "Focus on conciseness, clarity, and avoiding unnecessary repetition in the prompt structure.",
        "testStrategy": "Manual review of updated prompt templates. Compare token counts of old vs. new templates with similar data inputs.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 63,
        "title": "Add Detailed LLM Process Logging",
        "description": "Implement comprehensive logging in 'analysis_llm.py' to record key metrics at various stages of prompt generation and LLM interaction.",
        "details": "Log input row counts, applied truncation/sampling rules, estimated token counts, and final prompt length. Use INFO/WARN levels as appropriate for monitoring and debugging.",
        "testStrategy": "Review logs during development and testing to ensure all required information is captured accurately.",
        "priority": "high",
        "dependencies": [
          58,
          59,
          60,
          61,
          62
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 64,
        "title": "Implement 'results_overview' Generation Logic",
        "description": "Develop the logic within 'analysis_llm.py' to parse the LLM's raw output and extract key findings, summaries, and alerts, structuring them into the 'results_overview' field.",
        "details": "This field should provide a concise, human-readable summary suitable for quick display in dashboards.",
        "testStrategy": "Unit tests for the parsing and summarization logic. Integration tests to verify 'results_overview' is correctly populated after LLM calls.",
        "priority": "high",
        "dependencies": [
          57
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 65,
        "title": "Implement 'analysis_raw_compact' Generation Logic",
        "description": "Develop the logic to process and store a compact or summarized version of the raw analysis data (e.g., top-k segments, percentiles, notes) into the 'analysis_raw_compact' field.",
        "details": "Ensure this field adheres to the defined size limits ('max_raw_bytes') and contains sufficient information for forensic analysis without being excessively large.",
        "testStrategy": "Unit tests for the compaction logic. Integration tests to verify 'analysis_raw_compact' is correctly populated and within size limits.",
        "priority": "high",
        "dependencies": [
          57,
          56
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 66,
        "title": "Enhance '_to_stats()' Function",
        "description": "Modify the '_to_stats()' function to optionally include additional statistical measures like 'count', 'std' (standard deviation), 'min', and 'max' alongside 'avg' for KPIs.",
        "details": "This enhancement provides richer statistical context for the 'stats' array stored in the database.",
        "testStrategy": "Unit tests for '_to_stats()' to confirm correct calculation and inclusion of new statistical measures.",
        "priority": "medium",
        "dependencies": [],
        "status": "todo",
        "subtasks": []
      },
      {
        "id": 67,
        "title": "Update POST /api/analysis/results Endpoint",
        "description": "Ensure the FastAPI endpoint for creating analysis results correctly receives and processes the new 'results_overview' and 'analysis_raw_compact' fields from the incoming payload.",
        "details": "Verify Pydantic validation and correct mapping of these fields to the MongoDB schema during the save operation.",
        "testStrategy": "API integration tests for POST requests, verifying that new fields are correctly stored in MongoDB.",
        "priority": "high",
        "dependencies": [
          57,
          64,
          65
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 68,
        "title": "Update GET /api/analysis/results (List) Endpoint",
        "description": "Modify the FastAPI router for the analysis results list view to include 'results_overview' in the default projection and explicitly exclude 'analysis_raw_compact' to keep responses lightweight.",
        "details": "Optimize query performance for list retrieval by only fetching essential fields.",
        "testStrategy": "API integration tests for GET list requests, verifying the response structure and performance. Ensure 'analysis_raw_compact' is not present by default.",
        "priority": "high",
        "dependencies": [
          57
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 69,
        "title": "Update GET /api/analysis/results/{id} (Detail) Endpoint",
        "description": "Implement support for a query parameter (e.g., '?includeRaw=true') to optionally include the 'analysis_raw_compact' field in the detailed response for a specific analysis result.",
        "details": "The default response for the detail endpoint should exclude 'analysis_raw_compact' to maintain performance.",
        "testStrategy": "API integration tests for GET detail requests, verifying both default behavior and behavior with '?includeRaw=true' parameter.",
        "priority": "high",
        "dependencies": [
          57
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 70,
        "title": "Implement MongoDB Document Size Check",
        "description": "Add a check before saving documents to MongoDB to ensure they do not exceed the 16MB document size limit. Log warnings if the document size approaches or exceeds this limit.",
        "details": "Consider implementing compression or partial storage strategies if documents consistently hit the limit, though initial focus is on logging.",
        "testStrategy": "Unit tests for the size check logic. Integration tests simulating large documents to trigger warning logs.",
        "priority": "high",
        "dependencies": [
          67
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 71,
        "title": "Develop A/B Testing Framework",
        "description": "Create a framework to run 'analysis_llm.py' with both old and new configurations (token stabilization, payload strategy) using identical inputs.",
        "details": "The framework should capture and compare key metrics such as LLM token usage, processing time, and generated payload size for both paths.",
        "testStrategy": "Verify the framework can execute both old and new paths and collect the required metrics accurately.",
        "priority": "high",
        "dependencies": [
          63,
          67
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 72,
        "title": "Conduct A/B Testing & Analyze Results",
        "description": "Execute the A/B tests using the developed framework and analyze the collected data to compare performance, token efficiency, and payload size between the old and new paths.",
        "details": "Generate a report summarizing findings, identifying improvements and any regressions.",
        "testStrategy": "Review the A/B test report and confirm that the acceptance criteria for token usage and payload size are met.",
        "priority": "high",
        "dependencies": [
          71
        ],
        "status": "todo",
        "subtasks": []
      },
      {
        "id": 73,
        "title": "Implement End-to-End Integration Test",
        "description": "Develop an E2E test case that simulates the full analysis flow: triggering LLM analysis ('/api/analysis/trigger-llm-analysis'), MongoDB storage, and subsequent API retrieval ('GET /api/analysis/results' list and detail views).",
        "details": "Verify data integrity, correct API responses, and overall system functionality.",
        "testStrategy": "Execute the E2E test successfully, ensuring all components interact as expected and data is consistent.",
        "priority": "high",
        "dependencies": [
          67,
          68,
          69
        ],
        "status": "todo",
        "subtasks": []
      },
      {
        "id": 74,
        "title": "Verify Legacy Document Compatibility",
        "description": "Ensure that existing documents in MongoDB (potentially with camelCase keys or older structures) can still be correctly retrieved and processed by the updated backend.",
        "details": "Test with a representative sample of legacy data. Document any necessary migration steps or long-term compatibility plans if full backward compatibility is not feasible.",
        "testStrategy": "Run API queries against a database containing legacy documents and verify correct data retrieval and parsing.",
        "priority": "high",
        "dependencies": [
          68,
          69
        ],
        "status": "todo",
        "subtasks": []
      },
      {
        "id": 75,
        "title": "Set Up Backend Monitoring for Response/Document Size",
        "description": "Integrate metrics collection for backend API response sizes and MongoDB stored document sizes into the existing monitoring system.",
        "details": "Configure alerts for defined warning thresholds to proactively identify potential issues with payload bloat.",
        "testStrategy": "Verify that metrics are being collected and displayed in the monitoring dashboard, and that alerts trigger correctly when thresholds are met.",
        "priority": "medium",
        "dependencies": [
          70
        ],
        "status": "todo",
        "subtasks": []
      },
      {
        "id": 76,
        "title": "Implement Enhanced Error Logging for LLM Failures",
        "description": "Improve error logging for LLM call failures to include relevant context such as partial prompts, applied upper limits, and summaries of sampling results.",
        "details": "This will significantly aid in debugging 'max token exceed' errors or other LLM-related issues by providing more insight into the state at the time of failure.",
        "testStrategy": "Simulate LLM failures and verify that detailed context is captured in the logs.",
        "priority": "medium",
        "dependencies": [
          63
        ],
        "status": "todo",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-08-08T16:22:51.535Z",
      "updated": "2025-08-21T14:37:05.334Z",
      "description": "Tasks for master context"
    }
  }
}