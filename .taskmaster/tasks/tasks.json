{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Initialize React Frontend & State Management",
        "description": "Set up the React 18+ project, integrate Context API for global state management, and define the initial application structure.",
        "details": "Use Vite or Create React App for project initialization. Configure Context API for `userSettings` state management. Ensure basic routing is in place if not already. Implement a root Context Provider for application-wide state.",
        "testStrategy": "Verify project compiles and runs without errors. Create a simple test component to confirm Context API state can be accessed and updated using React Testing Library.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Initialize React Project",
            "description": "Set up a new React 18+ project using either Vite or Create React App, ensuring a clean initial setup.",
            "dependencies": [],
            "details": "Use `npm create vite@latest` (recommended for speed) or `npx create-react-app` to scaffold the project. Ensure React 18+ is installed. Remove any unnecessary boilerplate code.",
            "status": "done",
            "testStrategy": "Verify the project compiles and runs successfully by executing `npm run dev` (Vite) or `npm start` (CRA) and accessing it in a web browser."
          },
          {
            "id": 2,
            "title": "Implement Basic Client-Side Routing",
            "description": "Set up a foundational routing structure for the React application to enable navigation between different views.",
            "dependencies": [
              "1.1"
            ],
            "details": "Install `react-router-dom`. Define a basic routing structure in `App.jsx` or `App.tsx` with at least a home page and a placeholder settings page component. Use `BrowserRouter` and `Routes` components.\n<info added on 2025-08-21T18:12:03.058Z>\nExisting implementation found: `react-router-dom` v7.6.1 is already installed. Routing is handled in `App.jsx` via a state-based `activeMenu` approach, rather than `BrowserRouter`/`Routes`. Configured routes include: dashboard (default), results, statistics, preference (new), preference-old, preference-test, and llm-analysis. Sidebar navigation is also implemented via `Layout.jsx`.\n</info added on 2025-08-21T18:12:03.058Z>",
            "status": "done",
            "testStrategy": "Manually navigate between the defined routes in the browser to ensure they load correctly without errors. Verify the URL changes appropriately."
          },
          {
            "id": 3,
            "title": "Define userSettings Context and State Logic",
            "description": "Create the React Context for `userSettings`, define its initial state structure, and implement the state management logic (e.g., using `useReducer` or `useState`).",
            "dependencies": [
              "1.1"
            ],
            "details": "Create a dedicated file (e.g., `src/contexts/UserSettingsContext.jsx` or `.tsx`). Define the `UserSettingsContext` using `React.createContext`. Implement a `UserSettingsProvider` component that manages the `userSettings` state (e.g., using `useReducer` for complex state or `useState` for simpler state) and provides it to children components. Define initial state based on expected `userSettings` structure.\n<info added on 2025-08-21T18:15:23.595Z>\nThe `userSettings` structure will be expanded to include `preferences` (with `dashboard`, `charts`, `filters`), `pegConfigurations` (array), and `statisticsConfigurations` (array), while maintaining backward compatibility with existing settings like `dashboardSettings` and `statisticsSettings`. The state management will be enhanced with `lastModified`, `version`, `syncStatus`, and `localStorageAvailable` fields, managed via `useReducer` with actions like `SET_SYNC_STATUS`, `SET_LOCAL_STORAGE_STATUS`, and `UPDATE_METADATA`. The `UserSettingsProvider` will expose functions for managing PEG and Statistics configurations, including `updatePegConfiguration`, `updateStatisticsConfiguration`, `removePegConfiguration`, `removeStatisticsConfiguration`, and `validateOrderIndependentSettings`. A `UserSettingsTest.jsx` component will be created to test these new features, accessible via a new '/user-settings-test' route in `App.jsx`.\n</info added on 2025-08-21T18:15:23.595Z>",
            "status": "done",
            "testStrategy": "Write a simple unit test for the `userSettings` reducer (if `useReducer` is used) to ensure state transitions are correct. For `useState`, ensure the initial state is correctly set."
          },
          {
            "id": 4,
            "title": "Integrate Root Context Provider",
            "description": "Wrap the entire React application with the `userSettings` Context Provider to make the state globally accessible to all components.",
            "dependencies": [
              "1.1",
              "1.3"
            ],
            "details": "Modify the application's entry point file (`src/main.jsx` for Vite or `src/index.js` for Create React App) to wrap the root `<App />` component with the `UserSettingsProvider` component created in the previous subtask.",
            "status": "done",
            "testStrategy": "No specific test strategy for this subtask; its successful integration will be verified by the next subtask's tests."
          },
          {
            "id": 5,
            "title": "Create Test Component and Verify Context API",
            "description": "Develop a simple React component to consume and display `userSettings` from the Context, and allow for basic updates to verify Context API functionality.",
            "dependencies": [
              "1.1",
              "1.3",
              "1.4"
            ],
            "details": "Create a `TestSettingsDisplay.jsx` component that uses `useContext(UserSettingsContext)` to access and display a specific `userSettings` property (e.g., a preference). Include a button or input field to trigger an update to this setting via a function provided by the context. Integrate this component into the main application or a dedicated test route.",
            "status": "done",
            "testStrategy": "Use React Testing Library to render `TestSettingsDisplay`. Assert that the initial `userSettings` state is correctly displayed. Simulate a user interaction (e.g., button click) to update the state, and then assert that the component's UI reflects the updated state, confirming Context API functionality."
          }
        ]
      },
      {
        "id": 2,
        "title": "Initialize FastAPI Backend & PostgreSQL Connection",
        "description": "Set up the FastAPI project, configure database connection to PostgreSQL, and establish the basic API structure.",
        "details": "Use `uvicorn` for the server and `SQLAlchemy` with `asyncpg` for PostgreSQL ORM/driver. Define initial database schema for the `userSettings` table, including fields like `id`, `userId`, `preferences`, `pegConfigurations`, `statisticsConfigurations`, `lastModified`, and `version`.",
        "testStrategy": "Write unit tests using `pytest` for database connection and basic CRUD operations on a dummy table. Create a simple test endpoint to verify database interaction.",
        "priority": "high",
        "dependencies": [],
        "status": "cancelled",
        "subtasks": [
          {
            "id": 1,
            "title": "Initialize FastAPI Project & Install Core Dependencies",
            "description": "Create the basic FastAPI project structure and install necessary Python packages including `fastapi`, `uvicorn`, `SQLAlchemy`, `asyncpg`, and `pydantic`.",
            "dependencies": [],
            "details": "Use `pip install fastapi uvicorn sqlalchemy asyncpg pydantic` (or equivalent with pipenv/poetry). Create a main application file (e.g., `main.py`) and initialize a `FastAPI` application instance.\n<info added on 2025-08-21T18:18:21.748Z>\nDependencies `fastapi`, `uvicorn`, `pydantic`, `sqlalchemy[asyncio]`, and `asyncpg` are confirmed installed. `alembic` has also been added for database migrations. The FastAPI project structure is fully established, and the main application file is initialized.\n</info added on 2025-08-21T18:18:21.748Z>",
            "status": "pending",
            "testStrategy": "Verify `uvicorn main:app --reload` runs without errors and a simple root endpoint (e.g., `/`) returns a basic 'Hello World' message, confirming the server is operational."
          },
          {
            "id": 2,
            "title": "Configure SQLAlchemy PostgreSQL Connection",
            "description": "Set up the database connection string and initialize the SQLAlchemy engine and session maker for asynchronous operations with PostgreSQL using `asyncpg`.",
            "dependencies": [
              "2.1"
            ],
            "details": "Define environment variables for PostgreSQL connection details (e.g., `DATABASE_URL`). Use `create_async_engine` to create an `AsyncEngine` and `async_sessionmaker` to create an `AsyncSessionLocal` for managing database sessions. Implement a dependency injection function for database sessions in FastAPI.",
            "status": "pending",
            "testStrategy": "Write a unit test using `pytest` to ensure the `AsyncEngine` can be created successfully and a basic connection can be established (e.g., by executing a simple `SELECT 1` query against the database)."
          },
          {
            "id": 3,
            "title": "Define `userSettings` Database Model",
            "description": "Create the SQLAlchemy ORM model for the `userSettings` table, mapping all specified fields (`id`, `userId`, `preferences`, `pegConfigurations`, `statisticsConfigurations`, `lastModified`, `version`) to appropriate SQLAlchemy column types.",
            "dependencies": [
              "2.2"
            ],
            "details": "Define a `Base` using `declarative_base()` and create a `UserSettings` class inheriting from `Base`. Map `id` as `Integer` (primary key), `userId` as `String`, `preferences`, `pegConfigurations`, `statisticsConfigurations` as `JSONB` (or `JSON`), `lastModified` as `DateTime`, and `version` as `Integer`.",
            "status": "pending",
            "testStrategy": "Write a unit test to instantiate the `UserSettings` model and verify its attributes match the expected Python types and that the column definitions are correctly set up (e.g., `__tablename__`, primary key, column types)."
          },
          {
            "id": 4,
            "title": "Implement Database Schema Initialization",
            "description": "Set up a mechanism to create the `userSettings` table in the PostgreSQL database based on the defined SQLAlchemy model, ensuring it's created if it doesn't already exist.",
            "dependencies": [
              "2.3"
            ],
            "details": "For initial setup, use `SQLAlchemy.MetaData.create_all` with the async engine. This can be triggered on application startup or via a dedicated script. Ensure the table creation is idempotent.",
            "status": "pending",
            "testStrategy": "Run a script or application startup that attempts to create the table. Verify the `userSettings` table exists in the PostgreSQL database by connecting with a database client or by executing a SQL query like `SELECT * FROM information_schema.tables WHERE table_name = 'userSettings';`."
          },
          {
            "id": 5,
            "title": "Create Test Endpoint for Database Verification",
            "description": "Develop a simple FastAPI endpoint (e.g., `/api/test-db`) that performs a basic database operation (e.g., inserting and retrieving a dummy `userSettings` record) to verify the connection and ORM are working correctly.",
            "dependencies": [
              "2.4"
            ],
            "details": "The endpoint should use the `AsyncSessionLocal` dependency to obtain a database session. It should attempt to create a dummy `UserSettings` entry, persist it, and then query it back. Return a success message or the retrieved data.",
            "status": "pending",
            "testStrategy": "Write an integration test using `pytest` and FastAPI's `TestClient` (or `httpx`) to call the `/api/test-db` endpoint. Assert that the endpoint returns a 200 OK status and the expected data, confirming successful database interaction and ORM functionality."
          }
        ]
      },
      {
        "id": 3,
        "title": "Implement User Settings Data Model (Frontend & Backend)",
        "description": "Define the `userSettings` data model in both frontend (TypeScript interfaces) and backend (Pydantic models/SQLAlchemy models) to ensure consistency.",
        "details": "Based on the PRD's `userSettings` JSON structure, create corresponding TypeScript interfaces for the frontend and Pydantic models for FastAPI, along with SQLAlchemy models for database interaction. Ensure all specified fields are correctly typed/defined.",
        "testStrategy": "Write unit tests for data model serialization/deserialization on both frontend (Jest) and backend (pytest). Verify schema validation for incoming API requests.",
        "priority": "high",
        "dependencies": [
          1,
          2
        ],
        "status": "cancelled",
        "subtasks": [
          {
            "id": 1,
            "title": "Analyze PRD and Define Canonical JSON Schema",
            "description": "Review the Product Requirements Document (PRD) to extract and document the precise `userSettings` JSON structure, including all fields, their types, and constraints.",
            "dependencies": [],
            "details": "This subtask involves thoroughly reading the PRD's section on `userSettings` to create a definitive blueprint for the data model. This blueprint will guide the implementation of models across all layers.\n<info added on 2025-08-21T18:22:54.162Z>\nUser reports that the backend for user settings is already fully implemented using FastAPI and MongoDB, including APIs for saving, loading, backup, and restore, and comprehensive Pydantic models. The user suggests skipping Task 3 as a result. However, this contradicts the current subtask's focus on 'SQLAlchemy ORM Models' and the broader project context (e.g., Tasks 6, 7, 9, 12) which explicitly specifies PostgreSQL for user settings persistence. Clarification is needed on whether to proceed with PostgreSQL/SQLAlchemy as planned or if the existing MongoDB implementation is now the definitive solution for user settings. If PostgreSQL is still the target, then the existing MongoDB implementation does not fulfill the requirements for this subtask or its dependent tasks.\n</info added on 2025-08-21T18:22:54.162Z>",
            "status": "pending",
            "testStrategy": "N/A (Documentation/Analysis task)"
          },
          {
            "id": 2,
            "title": "Implement SQLAlchemy ORM Models",
            "description": "Create the Python SQLAlchemy ORM models that define the database schema for `userSettings` in PostgreSQL.",
            "dependencies": [
              "3.1"
            ],
            "details": "Map the canonical JSON schema fields to SQLAlchemy columns, specifying data types, primary keys, unique constraints, and relationships. Include fields like `userId`, `lastModified`, and `version` as per project requirements.",
            "status": "pending",
            "testStrategy": "Write basic unit tests for model definition and column types using `pytest`, ensuring correct mapping to database types."
          },
          {
            "id": 3,
            "title": "Implement Pydantic Models for FastAPI",
            "description": "Develop Pydantic models for the backend to handle request validation, response serialization, and data integrity for `userSettings`.",
            "dependencies": [
              "3.1",
              "3.2"
            ],
            "details": "Define Pydantic models that align with the canonical JSON schema and can be used to validate incoming API payloads and serialize data for outgoing responses. Ensure type hints, default values, and validation rules are correctly applied.",
            "status": "pending",
            "testStrategy": "Write unit tests using `pytest` to verify Pydantic model validation (e.g., valid/invalid data, missing fields) and serialization/deserialization behavior."
          },
          {
            "id": 4,
            "title": "Implement TypeScript Interfaces for Frontend",
            "description": "Create TypeScript interfaces that accurately represent the `userSettings` data model for the frontend application.",
            "dependencies": [
              "3.1",
              "3.3"
            ],
            "details": "Define TypeScript interfaces that mirror the structure and types of the Pydantic models, ensuring strong type checking and consistency across the frontend application's data handling.",
            "status": "pending",
            "testStrategy": "Write unit tests using `Jest` to ensure TypeScript interfaces correctly define the expected data structure and types, potentially testing against sample JSON data."
          },
          {
            "id": 5,
            "title": "Implement Cross-Layer Data Model Consistency Tests",
            "description": "Develop comprehensive unit tests to ensure consistency and correct behavior of the `userSettings` data model across all implemented layers (SQLAlchemy, Pydantic, TypeScript).",
            "dependencies": [
              "3.2",
              "3.3",
              "3.4"
            ],
            "details": "This involves writing tests that verify data can be correctly serialized from Pydantic to JSON, deserialized from JSON to Pydantic, and that SQLAlchemy models can represent this data. For frontend, ensure TypeScript interfaces correctly map to expected API responses.",
            "status": "pending",
            "testStrategy": "Use `pytest` for backend model serialization/deserialization and schema validation. Use `Jest` for frontend interface validation against expected data structures."
          }
        ]
      },
      {
        "id": 4,
        "title": "Develop LocalStorage-based Settings Save/Load",
        "description": "Implement logic to save and load user settings to/from LocalStorage upon user actions and page load/refresh.",
        "details": "Use `localStorage.setItem()` and `localStorage.getItem()`. Implement a custom React Hook or Context Provider to manage LocalStorage interactions, ensuring data is stringified/parsed correctly. Implement basic error handling for `QuotaExceededError` and other LocalStorage issues.",
        "testStrategy": "Write integration tests using React Testing Library to simulate page refresh and verify settings persistence. Use Jest mocks for `localStorage` to control test scenarios.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define LocalStorage Settings Schema and Utility Functions",
            "description": "Based on the `userSettings` data model (from Task 3), define the specific schema for how settings will be stored in LocalStorage. Create utility functions for serializing (stringifying) and deserializing (parsing) this data, ensuring type safety.",
            "dependencies": [],
            "details": "Create TypeScript interfaces for the LocalStorage specific settings structure. Implement `serializeSettings(settings)` and `parseSettings(jsonString)` functions using `JSON.stringify` and `JSON.parse`, including `try-catch` for parsing errors.\n<info added on 2025-08-21T18:25:40.975Z>\nImplemented TypeScript interfaces for `UserSettings`, `DashboardPreferences`, `ChartPreferences`, `FilterPreferences`, `PegConfiguration`, `StatisticsConfiguration`, and `LocalStorageSettings` (including metadata). Enhanced `serializeSettings` with checksum and size checks, and `deserializeSettings` (formerly `parseSettings`) with version validation and integrity checks. Added `saveSettingsToLocalStorage` (with `QuotaExceededError` handling), `loadSettingsFromLocalStorage` (with safe loading and error handling), `clearSettingsFromLocalStorage`, `checkLocalStorageAvailability`, and `getLocalStorageUsage` utilities. Advanced features include 5MB limit checks, data integrity checksums, version compatibility validation, detailed error classification/logging, and type safety.\n</info added on 2025-08-21T18:25:40.975Z>",
            "status": "done",
            "testStrategy": "Unit tests for serialization/deserialization utility functions, ensuring correct handling of valid and invalid JSON strings, and edge cases (e.g., null, undefined values)."
          },
          {
            "id": 2,
            "title": "Develop Custom React Hook/Context for LocalStorage Management",
            "description": "Create a reusable custom React Hook (e.g., `useLocalStorageSettings`) or a Context Provider that encapsulates the core logic for interacting with `localStorage`. This component will manage the state of settings and provide methods for updating them.",
            "dependencies": [
              "4.1"
            ],
            "details": "Implement `useLocalStorageSettings` hook. It should internally use `localStorage.setItem` and `localStorage.getItem`. It should expose a state variable for settings and a setter function. The hook should handle initial loading from LocalStorage.\n<info added on 2025-08-21T18:28:27.726Z>\nThe implementation must also include full TypeScript type safety, asynchronous load/save functions, detailed and granular error handling (e.g., `QUOTA_EXCEEDED`, `PARSE_ERROR`) with user-friendly messages and automatic recovery attempts (e.g., removing corrupted data). It should offer real-time usage monitoring (updated every 30 seconds), a debug logging option, and a callback system (onError, onLoad, onSave). Furthermore, it needs to integrate with and upgrade the existing `PreferenceContext`, providing logic for converting between old and new settings structures and maintaining backward compatibility. Advanced features such as an auto-load option, availability check (`checkAvailability`), and `isLoading`, `isSaving` status tracking are also required.\n</info added on 2025-08-21T18:28:27.726Z>",
            "status": "done",
            "testStrategy": "Unit tests for the custom hook using React Testing Library's `renderHook` to verify state management, initial load, and updates. Mock `localStorage` to control test scenarios."
          },
          {
            "id": 3,
            "title": "Implement Settings Save Logic on User Actions",
            "description": "Integrate the custom React Hook/Context Provider to save user settings to LocalStorage whenever a setting is changed by the user.",
            "dependencies": [
              "4.2"
            ],
            "details": "Within the components where settings are modified, use the setter function provided by `useLocalStorageSettings` (or the Context API) to update the settings state, which will trigger the save to LocalStorage. Ensure debouncing or throttling if frequent updates are expected.",
            "status": "done",
            "testStrategy": "Integration tests using React Testing Library to simulate user interactions (e.g., changing a toggle, inputting text) and verify that `localStorage.setItem` is called with the correct data."
          },
          {
            "id": 4,
            "title": "Implement Settings Load Logic on Page Load/Refresh",
            "description": "Implement the logic to load user settings from LocalStorage when the application initializes or the page is refreshed.",
            "dependencies": [
              "4.2"
            ],
            "details": "The custom React Hook/Context Provider developed in 4.2 should handle the initial load from LocalStorage when it is first mounted/initialized. This involves calling `localStorage.getItem` and parsing the stored string.",
            "status": "done",
            "testStrategy": "Integration tests using React Testing Library to simulate a component mounting (representing page load) and verify that settings are correctly retrieved from `localStorage` and applied to the component's state. Use Jest mocks for `localStorage.getItem`."
          },
          {
            "id": 5,
            "title": "Implement Basic LocalStorage Error Handling",
            "description": "Add error handling mechanisms for common LocalStorage issues, specifically `QuotaExceededError`, but also general read/write errors.",
            "dependencies": [
              "4.2"
            ],
            "details": "Wrap `localStorage.setItem` and `localStorage.getItem` calls within `try-catch` blocks. For `QuotaExceededError`, provide a user-friendly notification (e.g., a toast message) and potentially fall back to a default state or prevent further saves. Log other errors for debugging.",
            "status": "done",
            "testStrategy": "Unit tests for the custom hook/context that mock `localStorage` to throw `QuotaExceededError` or other exceptions during `setItem`/`getItem` calls, verifying that the error handling logic is triggered and appropriate actions (e.g., logging, user notification) are taken."
          }
        ]
      },
      {
        "id": 5,
        "title": "Implement Settings Save Status UI & Basic Error Feedback",
        "description": "Create UI elements to clearly indicate the status of setting saves (e.g., 'Saving...', 'Saved!', 'Error saving').",
        "details": "Integrate status indicators (e.g., toast notifications, status bar, or inline messages) into the dashboard UI. Implement basic error handling for LocalStorage operations, displaying user-friendly messages for failures.",
        "testStrategy": "Manually test UI feedback for successful saves and simulated errors. Write unit tests for UI component rendering based on different saving states (idle, saving, saved, error).",
        "priority": "medium",
        "dependencies": [
          4
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Define UI States for Settings Save Status",
            "description": "Determine the visual representation and interaction patterns for settings save status (Idle, Saving, Saved, Error). This includes choosing the type of indicator (e.g., toast, inline message, status bar) and defining the specific messages and styling for each state.",
            "dependencies": [],
            "details": "Research common UI patterns for save status feedback. Create mockups or detailed specifications for 'Saving...', 'Saved!', and 'Error saving' states, considering placement within the dashboard UI. Ensure consistency with existing UI/UX guidelines.\n<info added on 2025-08-21T18:36:52.000Z>\n구현 내용:\n1. **상태 타입 정의**: SAVE_STATUS (IDLE, SAVING, SAVED, ERROR)\n2. **UI 패턴 결정**:\n   - Toast 알림 (sonner 기반)\n   - 인라인 상태 표시 (SaveStatusIndicator)\n   - 고정 위치 표시 옵션\n   - 아이콘 + 텍스트 조합\n\n3. **시각적 표현**:\n   - SAVING: 회전하는 Loader2 아이콘 + 파란색\n   - SAVED: CheckCircle 아이콘 + 초록색 + 자동 숨김\n   - ERROR: AlertCircle 아이콘 + 빨간색 + 액션 버튼\n\n4. **사용자 경험**:\n   - 자동 숨김 (3초)\n   - 애니메이션 효과\n   - 접근성 고려\n   - 다양한 variant (default, compact, icon-only)\n\n기존 sonner toast 시스템과 완벽하게 통합되어 일관된 UI/UX를 제공합니다.\n</info added on 2025-08-21T18:36:52.000Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement Core UI Components for Status Display",
            "description": "Develop reusable front-end UI components capable of displaying the defined save status messages and indicators. These components should be generic enough to accept a status prop and render accordingly.",
            "dependencies": [
              "5.1"
            ],
            "details": "Create a dedicated React/Vue/Angular component (e.g., `SaveStatusIndicator` or `ToastNotification`) that can be triggered to show different states. Ensure the components are styled appropriately and are accessible.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Integrate UI Status with Successful Settings Save Flow",
            "description": "Connect the implemented UI components to the settings saving mechanism. When a user initiates a save operation, the UI should immediately transition to a 'Saving...' state, and upon successful completion, transition to a 'Saved!' state, typically fading out after a short delay.",
            "dependencies": [
              "5.2"
            ],
            "details": "Modify the existing settings save function (which currently interacts with LocalStorage) to dispatch status updates to the UI components. Implement logic to show 'Saving...' during the `localStorage.setItem` call and 'Saved!' on success, with a configurable display duration for 'Saved!'.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Implement Basic Error Handling for LocalStorage Operations",
            "description": "Add `try-catch` blocks or similar error handling mechanisms around LocalStorage operations (e.g., `localStorage.setItem`) to gracefully capture failures. When an error occurs, the UI should display a user-friendly 'Error saving' message.",
            "dependencies": [
              "5.2"
            ],
            "details": "Identify potential LocalStorage errors (e.g., `QuotaExceededError`, `SecurityError`, `InvalidStateError`). Implement error capture within the settings save function and pass the error state to the UI components. Display a clear, actionable error message to the user, potentially with details for debugging.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Write Unit Tests for UI Status Component Rendering",
            "description": "Develop unit tests for the UI components responsible for displaying save status. These tests should verify that the components render correctly for each defined state: idle, saving, saved, and error.",
            "dependencies": [
              "5.2",
              "5.3",
              "5.4"
            ],
            "details": "Use a testing framework (e.g., Jest, React Testing Library) to simulate different status inputs (props) to the UI components and assert that the correct text, styling, and elements are rendered. Test edge cases like rapid state changes and ensure error messages are displayed correctly.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 6,
        "title": "Implement `/api/settings/save` Endpoint",
        "description": "Create a FastAPI endpoint to receive and persist user settings to the PostgreSQL database.",
        "details": "The endpoint should accept the `userSettings` data model, validate it using Pydantic, and save it to PostgreSQL. Implement logic to handle updates (if settings for `userId` exist) or inserts. Ensure `lastModified` and `version` fields are correctly updated on each save.",
        "testStrategy": "Write API integration tests using `pytest` to verify data persistence, correct response codes (200 OK, 400 Bad Request), and proper handling of existing vs. new user settings.",
        "priority": "high",
        "dependencies": [],
        "status": "cancelled",
        "subtasks": [
          {
            "id": 1,
            "title": "Define UserSettings Pydantic Model and Database Schema",
            "description": "Create the Pydantic `UserSettings` data model for request validation and define the corresponding PostgreSQL table schema. This includes fields like `userId`, `settingsData` (JSONB), `lastModified` (timestamp), and `version` (integer).",
            "dependencies": [],
            "details": "Define `UserSettings` Pydantic model with appropriate types and validation rules. Design the `user_settings` table in PostgreSQL, ensuring columns for `user_id`, `settings_data` (JSONB), `last_modified` (timestamp with timezone), and `version` (integer). Consider primary keys and unique constraints (e.g., `user_id` as unique).",
            "status": "pending",
            "testStrategy": "N/A (Schema definition is not directly testable via API tests, but its correctness will be verified by subsequent tasks)."
          },
          {
            "id": 2,
            "title": "Implement Settings Database Operations (Upsert Logic)",
            "description": "Develop the functions within the database access layer responsible for interacting with the PostgreSQL `user_settings` table. This includes functions to check for existing settings, insert new records, and update existing ones, incorporating `lastModified` and `version` logic.",
            "dependencies": [
              "6.1"
            ],
            "details": "Create a function `get_user_settings(user_id)` to retrieve existing settings. Create a function `insert_user_settings(user_id, settings_data)` for new entries. Create a function `update_user_settings(user_id, settings_data, current_version)` for existing entries, handling version increment and `lastModified` update. Implement the core upsert logic within this layer, ensuring atomic operations where possible.",
            "status": "pending",
            "testStrategy": "Write unit tests for the database functions to ensure correct data manipulation, versioning, and timestamp updates."
          },
          {
            "id": 3,
            "title": "Develop /api/settings/save FastAPI Endpoint Structure",
            "description": "Set up the basic FastAPI endpoint at `/api/settings/save`. Define the request method (POST/PUT) and ensure it correctly receives and validates the `UserSettings` Pydantic model from the request body.",
            "dependencies": [
              "6.1"
            ],
            "details": "Define the FastAPI route for `/api/settings/save`. Specify the HTTP method (e.g., `POST`). Use Pydantic model as the request body type hint for automatic validation. Implement basic error handling for Pydantic validation failures (FastAPI handles this by default, but ensure it's configured correctly).",
            "status": "pending",
            "testStrategy": "Write unit tests for the endpoint to verify it accepts valid `UserSettings` data and returns 422 (Unprocessable Entity) for invalid data, leveraging FastAPI's built-in validation."
          },
          {
            "id": 4,
            "title": "Implement Save Endpoint Business Logic (Upsert and Versioning)",
            "description": "Integrate the database access layer functions into the `/api/settings/save` endpoint. Implement the full business logic for saving settings, including checking for existing settings, performing an insert or update, and correctly managing the `lastModified` timestamp and `version` number.",
            "dependencies": [
              "6.2",
              "6.3"
            ],
            "details": "Inside the endpoint, retrieve the `userId` (e.g., from authentication context or request body if applicable). Call the database layer to check if settings exist for the `userId`. If settings exist, increment the `version` and update `lastModified` before calling the update function. If settings do not exist, set initial `version` to 1 and `lastModified` to current timestamp before calling the insert function. Return appropriate HTTP responses (e.g., 200 OK on success, 400 Bad Request for business logic errors).",
            "status": "pending",
            "testStrategy": "Focus on integration tests for the endpoint's business logic, ensuring correct upsert behavior, versioning, and timestamp updates."
          },
          {
            "id": 5,
            "title": "Write API Integration Tests for /api/settings/save",
            "description": "Create a comprehensive suite of API integration tests using `pytest` to verify the end-to-end functionality of the `/api/settings/save` endpoint.",
            "dependencies": [
              "6.4"
            ],
            "details": "Test cases for saving new user settings (insert). Test cases for updating existing user settings, verifying `lastModified` and `version` increments. Test cases for invalid input data (e.g., missing required fields, incorrect types) expecting 400/422 responses. Verify correct HTTP status codes (200 OK, 400 Bad Request, 422 Unprocessable Entity). Verify data persistence in the PostgreSQL database after each operation.",
            "status": "pending",
            "testStrategy": "Use `pytest` with `httpx` or FastAPI's `TestClient` to simulate API requests. Assert on response status codes, body content, and directly query the database to verify persistence and data integrity."
          }
        ]
      },
      {
        "id": 7,
        "title": "Implement `/api/settings/load` Endpoint",
        "description": "Create a FastAPI endpoint to retrieve user settings from the PostgreSQL database for a given user.",
        "details": "The endpoint should accept a `userId` (e.g., extracted from authentication context) and return the latest `userSettings` object. Handle cases where no settings exist for the user, returning an appropriate empty or default response.",
        "testStrategy": "Write API integration tests to verify correct data retrieval for existing and non-existing users. Test performance against the 50ms requirement.",
        "priority": "high",
        "dependencies": [
          6
        ],
        "status": "cancelled",
        "subtasks": [
          {
            "id": 1,
            "title": "Define User Settings Pydantic Models",
            "description": "Create the Pydantic models for `UserSettings` (representing the data stored in the DB) and the response model for the `/api/settings/load` endpoint. Ensure `userId`, `lastModified`, and `version` fields are included as per project context.",
            "dependencies": [],
            "details": "Define `UserSettings` Pydantic model with fields like `userId` (str), `lastModified` (datetime), `version` (int), and the actual settings data (e.g., `settings: Dict[str, Any]`). Also, define the Pydantic response model for the `/load` endpoint, which might be `Optional[UserSettings]` or a specific wrapper.",
            "status": "pending",
            "testStrategy": "N/A (Model definition is typically verified by subsequent code using it)"
          },
          {
            "id": 2,
            "title": "Implement User Settings Database Retrieval Logic",
            "description": "Develop the Python function(s) responsible for querying the PostgreSQL database to retrieve the latest `userSettings` record for a given `userId`.",
            "dependencies": [
              "7.1"
            ],
            "details": "Use an ORM (e.g., SQLAlchemy) or a database connector (e.g., `psycopg2`) to connect to PostgreSQL. Write a function `get_user_settings(user_id: str)` that queries the `user_settings` table, orders by `lastModified` or `version` to get the latest, and returns the data mapped to the `UserSettings` Pydantic model. Handle cases where no record is found by returning `None`.",
            "status": "pending",
            "testStrategy": "Write unit tests for the database retrieval function to ensure it correctly fetches data, handles `None` for non-existent users, and retrieves the latest version."
          },
          {
            "id": 3,
            "title": "Create FastAPI Endpoint Skeleton for /api/settings/load",
            "description": "Set up the basic FastAPI route for the `/api/settings/load` endpoint, defining its path, HTTP method (GET), and how `userId` will be received.",
            "dependencies": [
              "7.1"
            ],
            "details": "Define a FastAPI `APIRouter` and add a `GET` endpoint at `/api/settings/load`. Determine how `userId` will be passed (e.g., as a query parameter, path parameter, or extracted from a dependency injection for authentication context). Add type hints for the response model.",
            "status": "pending",
            "testStrategy": "Write a basic integration test to ensure the endpoint is reachable and returns a 200 OK (even if it's just an empty response initially)."
          },
          {
            "id": 4,
            "title": "Integrate DB Retrieval Logic and Handle Responses",
            "description": "Connect the FastAPI endpoint with the database retrieval logic and implement the response handling, including cases where no settings are found for the user.",
            "dependencies": [
              "7.2",
              "7.3"
            ],
            "details": "Inside the `/api/settings/load` endpoint function, call the `get_user_settings` function (from 7.2). If settings are found, return them as a JSON response. If no settings are found, return an appropriate default or empty `userSettings` object (e.g., `{'userId': user_id, 'settings': {}}`) with a 200 OK status, as per the parent task's requirement.",
            "status": "pending",
            "testStrategy": "Write integration tests to verify that the endpoint correctly returns existing settings, and returns an empty/default response for non-existent users."
          },
          {
            "id": 5,
            "title": "Implement API Integration and Performance Tests",
            "description": "Develop comprehensive API integration tests for the `/api/settings/load` endpoint, covering data retrieval for existing and non-existing users, and performance against the 50ms requirement.",
            "dependencies": [
              "7.4"
            ],
            "details": "Use `pytest` and an HTTP client (e.g., `httpx`) to send requests to the `/api/settings/load` endpoint. Include test cases for: 1) User with existing settings (verify data), 2) User with no settings (verify empty/default response), and 3) Performance test (measure response time and assert it's within 50ms).",
            "status": "pending",
            "testStrategy": "N/A (This subtask defines the test strategy itself)"
          }
        ]
      },
      {
        "id": 8,
        "title": "Develop Hybrid Settings Sync & Conflict Resolution",
        "description": "Implement the client-server synchronization logic, prioritizing server data on initial load and handling potential conflicts between local and server settings.",
        "details": "On app load, attempt to load from server first. If server data is newer or exists, use it. If local data is newer and server data is older/non-existent, implement a timestamp-based conflict resolution strategy (e.g., 'last write wins') or prompt the user for choice. Implement a background sync mechanism for continuous updates.",
        "testStrategy": "Use Playwright for E2E tests simulating different sync scenarios (e.g., offline changes, concurrent changes from multiple tabs/devices, server-side updates). Unit tests for conflict resolution logic.",
        "priority": "high",
        "dependencies": [
          4
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Initial Load Server-First Sync",
            "description": "Develop the logic to fetch user settings from the server upon application load. If server data is available and newer (or if no local data exists), prioritize and load the server's version of settings into the client's state.",
            "dependencies": [],
            "details": "Implement API call to fetch settings. Compare server timestamp with local timestamp (if local data exists). Update client state with server data if applicable. Ensure robust handling for server unavailability during initial load.\n<info added on 2025-08-21T18:53:54.447Z>\nRefine data comparison to identify field-level differences between local and server settings. Implement logic to detect concurrent modifications on specific fields, even if Last Write Wins is the default resolution strategy already implemented in 8.1. This will lay the groundwork for potential future enhancements like user-driven conflict resolution or detailed conflict reporting.\n</info added on 2025-08-21T18:53:54.447Z>",
            "status": "done",
            "testStrategy": "Unit tests for server data loading and timestamp comparison logic. Integration tests to verify client state updates based on server priority."
          },
          {
            "id": 2,
            "title": "Develop Local-Server Data Comparison & Pre-Conflict Logic",
            "description": "Implement the client-side logic to compare local settings data (from LocalStorage) with server settings data, specifically identifying scenarios where local data is newer or server data is missing, setting the stage for conflict resolution.",
            "dependencies": [
              "8.1"
            ],
            "details": "Retrieve local settings from LocalStorage. Compare timestamps of local and server settings. Determine if a conflict scenario (local data newer, server data older/non-existent) exists, and flag it for resolution.\n<info added on 2025-08-21T19:00:26.837Z>\nThis now includes an advanced data comparison system (`deepCompareObjects` for field-level differences, 6 `CONFLICT_TYPES`, `CONFLICT_SEVERITY`, `FIELD_IMPORTANCE`) and a comprehensive conflict analysis engine (`analyzeSettingsConflict`) for multi-faceted comparisons (timestamp, version, data content), automatic difference/severity calculation, and recommendation generation. An intelligent conflict resolution system (`generateConflictResolution`) provides AI-based strategy recommendations ('Last Write Wins', 'Manual Review', 'Safe Fallback') with confidence-based decisions. `PreferenceContext` was integrated to manage conflict state (`conflictAnalysis`, `conflictResolution`, `hasActiveConflict`) via dedicated reducer actions and functions. The `syncWithServer` logic was enhanced to use this analysis for intelligent auto-resolution vs. user intervention, with toast notifications and state cleanup.\n</info added on 2025-08-21T19:00:26.837Z>",
            "status": "done",
            "testStrategy": "Unit tests for timestamp comparison logic, covering cases where local is newer, server is newer, and timestamps are equal. Test conflict detection flags."
          },
          {
            "id": 3,
            "title": "Implement Conflict Resolution Strategy ('Last Write Wins')",
            "description": "Develop the core conflict resolution logic. If local data is newer than server data, implement a 'last write wins' timestamp-based strategy to determine the authoritative version and apply it to the client's state.",
            "dependencies": [
              "8.2"
            ],
            "details": "Based on the conflict detection from 8.2, apply 'last write wins' logic: the setting with the latest timestamp (either local or server) is chosen as the authoritative version. Update the client's settings state and persist the chosen version locally.\n<info added on 2025-08-21T19:06:28.545Z>\nThe 'last write wins' logic has been significantly enhanced beyond a simple timestamp comparison. The updated implementation now includes:\n*   **Advanced LWW Strategies**: A system (`lastWriteWinsUtils.js`) supporting multiple strategies: `STRICT_TIMESTAMP` (with refined timestamp analysis including time difference, recent conflict detection, and significant difference judgment), `HYBRID_METADATA`, `FIELD_LEVEL_LWW` (for individual field-level conflict analysis, win tally, and type/severity handling), `CONFIDENCE_WEIGHTED`, and `SMART_MERGE` (for intelligent, field-level confidence-based merging of settings, including nested objects).\n*   **Confidence-Based Resolution**: A 5-stage `CONFIDENCE_LEVELS` system dynamically calculates a confidence score, determining whether resolution is automatic (high confidence) or requires user intervention (medium/low confidence).\n*   **Comprehensive Orchestration**: A `comprehensiveLWW` orchestrator manages these strategies, enabling hybrid approaches and confidence-based strategy selection.\n*   **PreferenceContext Integration**: Core functions like `resolveLWWConflict`, `applyLWWResolution`, `autoResolveLWW`, and `previewLWWStrategies` are integrated.\n*   **Enhanced Sync Integration**: The `syncWithServer` process now fully leverages this advanced LWW system, providing confidence-based auto/manual branching, various resolution options, and UI feedback via toast notifications with confidence scores and action buttons.\n</info added on 2025-08-21T19:06:28.545Z>",
            "status": "done",
            "testStrategy": "Unit tests for 'last write wins' logic with various timestamp scenarios (local newer, server newer, equal, missing). Verify correct data selection and application."
          },
          {
            "id": 4,
            "title": "Develop Background Synchronization Mechanism",
            "description": "Implement a continuous background synchronization mechanism to push local changes to the server and pull server updates to the client, ensuring settings remain up-to-date across sessions and devices.",
            "dependencies": [
              "8.1",
              "8.3"
            ],
            "details": "Choose and implement a background sync strategy (e.g., periodic polling, WebSockets, or a combination). Implement logic to detect local changes and push them to the server. Implement logic to fetch server changes and apply them, utilizing the conflict resolution logic (8.3) if necessary.\n<info added on 2025-08-21T19:13:01.547Z>\nImplemented a comprehensive `BackgroundSyncManager` class in `backgroundSyncUtils.js` managing the full sync lifecycle with five strategies: PERIODIC_POLLING, VISIBILITY_BASED, CHANGE_TRIGGERED, HYBRID, and ON_DEMAND. Intelligent event-based triggers include online/offline status, page visibility, window focus/blur, and network quality monitoring. Local changes are detected via JSON serialization comparison with debouncing. Robust error handling incorporates up to 3 retries with exponential backoff (5s, 10s, 20s, max 5min) and automatic restart on network recovery. Fully integrated with `PreferenceContext` via dedicated functions (`startBackgroundSync`, `stopBackgroundSync`, `changeBackgroundSyncStrategy`, `forceBackgroundSync`, `getBackgroundSyncStatus`, `updateNetworkInfo`). Lifecycle management ensures auto-start 2 seconds post-initialization and complete resource cleanup on unmount. The system reuses `syncWithServer` for automatic 'Last Write Wins' conflict resolution (8.3) and consistent toast notifications. Performance is optimized through debouncing, pausing sync in background, and adaptive intervals based on network conditions.\n</info added on 2025-08-21T19:13:01.547Z>",
            "status": "done",
            "testStrategy": "Integration tests to verify background sync pushes local changes to the server. E2E tests (Playwright) to simulate concurrent changes from multiple tabs/devices and verify successful synchronization."
          },
          {
            "id": 5,
            "title": "Implement Comprehensive Error Handling & E2E Testing",
            "description": "Implement robust error handling for network issues, server unavailability, and data corruption during sync operations. Address edge cases like initial sync with no data, concurrent modifications, and offline-then-online scenarios. Conduct comprehensive E2E testing.",
            "dependencies": [
              "8.1",
              "8.2",
              "8.3",
              "8.4"
            ],
            "details": "Add try-catch blocks and retry mechanisms for API calls. Handle cases where server or local data is malformed or missing. Ensure graceful degradation or informative user feedback during sync failures. Conduct Playwright E2E tests simulating offline changes, concurrent changes, and server-side updates to validate the entire sync flow.",
            "status": "done",
            "testStrategy": "Playwright E2E tests for offline changes, concurrent changes from multiple tabs/devices, and server-side updates. Unit tests for specific error handling paths and edge case scenarios."
          }
        ]
      },
      {
        "id": 9,
        "title": "Implement `/api/settings/validate` Endpoint",
        "description": "Create a FastAPI endpoint to perform server-side validation of PEG and Statistics configurations, independent of their submission order.",
        "details": "This endpoint should receive partial or full settings and return validation results (e.g., `isValid: boolean`, `errors: []`, `suggestions: []`). It should identify missing dependencies (e.g., PostgreSQL connection required for PEG/Statistics) or inconsistencies within the provided configurations.",
        "testStrategy": "Write API integration tests to verify validation logic for various PEG/Statistics configurations, including valid, invalid, and partially dependent states. Ensure it correctly identifies missing prerequisites.",
        "priority": "medium",
        "dependencies": [],
        "status": "cancelled",
        "subtasks": [
          {
            "id": 1,
            "title": "Define /api/settings/validate Endpoint and Pydantic Models",
            "description": "Create the FastAPI route for `/api/settings/validate` (POST method). Define the Pydantic models for the incoming request body, allowing for partial settings (e.g., using `Optional` or `Field(default=None)`). Define the Pydantic model for the validation response, including `isValid: bool`, `errors: List[str]`, and `suggestions: List[str]` to structure the output.",
            "dependencies": [],
            "details": "Use `fastapi.APIRouter` to define the endpoint. Leverage `pydantic.BaseModel` for both the request payload (e.g., `SettingsValidationRequest`) and the response payload (e.g., `ValidationResult`). Ensure the request model can gracefully handle missing fields for partial validation.",
            "status": "pending",
            "testStrategy": "Write unit tests to verify that the Pydantic request model correctly parses valid and partial input data, and that the response model can be instantiated with expected data types."
          },
          {
            "id": 2,
            "title": "Implement Field-Level and Basic Configuration Validation",
            "description": "Develop the core validation functions for individual fields and basic structural integrity within the PEG and Statistics configuration sections. This includes type checking, range checks, format validation (e.g., regex for URLs/IPs), and ensuring required fields within a given sub-configuration are present if that sub-configuration is provided.",
            "dependencies": [
              "9.1"
            ],
            "details": "Create a dedicated validation module or class (e.g., `settings_validator.py`). Implement specific functions for validating PEG-related fields and Statistics-related fields. Each validation function should return a list of specific error messages or suggestions for invalid inputs.",
            "status": "pending",
            "testStrategy": "Write comprehensive unit tests for each individual validation function, covering valid inputs, invalid data types, out-of-range values, and missing required fields within a provided sub-configuration."
          },
          {
            "id": 3,
            "title": "Implement Inter-Configuration and External Dependency Validation",
            "description": "Develop logic to validate relationships *between* different configuration sections (e.g., if PEG is enabled, ensure specific related settings are configured). Crucially, implement checks for external dependencies, such as verifying that PostgreSQL connection details are provided and valid if PEG or Statistics features are enabled, as stated in the parent task. This should identify missing prerequisites.",
            "dependencies": [
              "9.1",
              "9.2"
            ],
            "details": "This logic will operate on the potentially partial settings object. It should identify logical inconsistencies (e.g., feature X enabled but dependent feature Y disabled) or missing prerequisites (e.g., PostgreSQL host/port/credentials missing when PEG/Statistics are active). Focus on checking for the *presence* and *syntactic validity* of connection parameters, not necessarily establishing a live connection.",
            "status": "pending",
            "testStrategy": "Write unit tests for dependency checks, covering scenarios where dependencies are fully met, partially met, or entirely missing. Include tests for conflicting configurations and logical inconsistencies."
          },
          {
            "id": 4,
            "title": "Integrate Validation Logic and Construct API Response",
            "description": "Integrate the field-level validation (from 9.2) and the cross-configuration/dependency validation (from 9.3) into the `/api/settings/validate` endpoint. The endpoint logic will orchestrate the validation process, collect all errors and suggestions from various validation steps, determine the overall `isValid` status, and construct the final `ValidationResult` response object. Ensure it correctly handles partial input, only validating provided sections but still checking dependencies if relevant sections are present.",
            "dependencies": [
              "9.1",
              "9.2",
              "9.3"
            ],
            "details": "The FastAPI endpoint function will call the appropriate validation functions, aggregate their results into a single list of errors and suggestions. The `isValid` flag in the response should be `True` only if no errors are found across all validation checks. Implement logic to ensure validation is performed only on the parts of the settings provided in the request, while still checking for cross-dependencies if the relevant sections are present.",
            "status": "pending",
            "testStrategy": "Perform API integration tests using `pytest` to verify the endpoint's overall behavior. Test with various combinations of valid, invalid, and partial settings to ensure correct aggregation of errors/suggestions and accurate `isValid` status."
          },
          {
            "id": 5,
            "title": "Develop Comprehensive API Integration Tests for Validation Endpoint",
            "description": "Write a comprehensive suite of API integration tests for the `/api/settings/validate` endpoint. These tests should cover a wide range of scenarios, including: valid full configurations, valid partial configurations, invalid configurations (e.g., wrong data types, out-of-range values), configurations with missing internal dependencies (e.g., PEG enabled but required sub-field missing), and configurations with missing external dependencies (e.g., PEG/Statistics enabled but PostgreSQL details absent). Verify correct `isValid` status, error messages, and suggestions.",
            "dependencies": [
              "9.4"
            ],
            "details": "Use `pytest` and FastAPI's `TestClient` to simulate API requests. Define clear test cases for each validation rule and dependency check. Focus on end-to-end verification of the endpoint's behavior, ensuring all specified validation criteria from the parent task are met.",
            "status": "pending",
            "testStrategy": "Ensure high test coverage for the validation logic by creating diverse test payloads. Include tests for edge cases and boundary conditions to confirm robustness."
          }
        ]
      },
      {
        "id": 10,
        "title": "Develop Order-Independent Configuration Logic (Frontend)",
        "description": "Enhance the frontend to allow PEG and Statistics settings to be configured in any order, using the backend validation API and providing smart guidance.",
        "details": "Integrate the `/api/settings/validate` endpoint to perform real-time validation. Implement frontend logic to re-evaluate configuration validity dynamically as users input data. Use Context API to manage the state of PEG/Statistics configurations and their interdependencies.",
        "testStrategy": "Use React Testing Library to simulate user input sequences for PEG/Statistics and verify correct validation feedback. E2E tests with Playwright for full user flow, ensuring order independence.",
        "priority": "high",
        "dependencies": [
          8,
          9
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Establish Frontend Configuration State Management with Context API",
            "description": "Design and implement a React Context API provider to centrally manage the state of PEG and Statistics configurations, including their interdependencies. This context will serve as the single source of truth for all configuration settings and their current validity status.",
            "dependencies": [],
            "details": "Create a `SettingsProvider` component and a `useSettings` hook. Define the shape of the configuration state (e.g., `pegSettings`, `statsSettings`, `validationResults`). Implement reducer logic or state update functions to modify these settings and their associated validation states.",
            "status": "pending",
            "testStrategy": "Unit tests for the Context Provider and reducer logic to ensure state updates and initial state are correct."
          },
          {
            "id": 2,
            "title": "Integrate Backend Validation Endpoint (`/api/settings/validate`)",
            "description": "Develop the frontend service layer responsible for making real-time API calls to the `/api/settings/validate` endpoint. This service will send the current configuration state and receive validation feedback.",
            "dependencies": [
              "10.1"
            ],
            "details": "Create an API utility function (e.g., `validateSettingsApi`) that takes the current `userSettings` object as input, performs an asynchronous POST request to `/api/settings/validate`, and returns the parsed validation response. Implement basic error handling for network issues or API errors.",
            "status": "pending",
            "testStrategy": "Mock the API call using Jest/MSW to ensure the request payload is correct and the response is handled properly."
          },
          {
            "id": 3,
            "title": "Implement Dynamic Configuration Re-evaluation Logic",
            "description": "Develop the frontend logic within the configuration components to dynamically re-evaluate the validity of PEG and Statistics settings as users input data. This involves triggering validation calls and updating the UI state.",
            "dependencies": [
              "10.1",
              "10.2"
            ],
            "details": "Within the PEG and Statistics configuration components, use `useEffect` hooks to detect changes in input fields. On change, debounce the input and then call the `validateSettingsApi` (from 10.2) with the current configuration state (from 10.1). Update the `validationResults` within the `SettingsContext` based on the API response.",
            "status": "pending",
            "testStrategy": "Use React Testing Library to simulate user input events and verify that the validation API is called with the correct payload and that the context state is updated."
          },
          {
            "id": 4,
            "title": "Develop Smart Guidance and Real-time Feedback UI",
            "description": "Design and implement the user interface components responsible for displaying real-time validation feedback, including error messages, warnings, and 'smart guidance,' based on the `validationResults` from the Context API.",
            "dependencies": [
              "10.1",
              "10.3"
            ],
            "details": "Create UI components that consume the `validationResults` from the `SettingsContext` (10.1). Conditionally render error messages next to specific input fields, highlight invalid sections, and display contextual 'smart guidance' messages to help users resolve configuration issues or suggest optimal settings. Ensure accessibility and clear visual cues.",
            "status": "pending",
            "testStrategy": "Use React Testing Library to render components with different `validationResults` states and assert that the correct error messages, warnings, and guidance are displayed."
          },
          {
            "id": 5,
            "title": "Verify Order-Independent Configuration Flow with Comprehensive Testing",
            "description": "Conduct thorough testing to ensure the entire configuration system functions correctly regardless of the order in which PEG and Statistics settings are modified, confirming the 'order-independent' requirement.",
            "dependencies": [
              "10.1",
              "10.2",
              "10.3",
              "10.4"
            ],
            "details": "This subtask focuses on the comprehensive testing strategy for the integrated components.",
            "status": "pending",
            "testStrategy": "Use React Testing Library to simulate various user input sequences for PEG and Statistics settings (e.g., entering PEG data first, then Statistics; entering Statistics first, then PEG; making partial inputs; correcting errors) and verify that the correct validation feedback is displayed at each step. Implement E2E tests with Playwright to simulate full user flows, including navigating to settings, modifying PEG and Statistics in different orders, and observing real-time validation."
          }
        ]
      },
      {
        "id": 11,
        "title": "Implement Intuitive Configuration Guidance UI",
        "description": "Design and implement clear, contextual guidance messages for users during the configuration process, especially regarding PEG/Statistics dependencies.",
        "details": "Based on validation results from Task 10, display actionable messages (e.g., 'Please configure PostgreSQL first', 'Missing required field X'). Utilize UI patterns like tooltips, inline error messages, or guided wizards to improve user experience.",
        "testStrategy": "Conduct UI/UX review with target personas. Perform user acceptance testing (UAT) to ensure messages are clear and helpful. Verify messages appear correctly for various validation states.",
        "priority": "medium",
        "dependencies": [
          10
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Research and Design UI Patterns for Configuration Guidance",
            "description": "Analyze the types of validation messages expected from Task 9 (e.g., missing fields, dependency issues like 'PostgreSQL first'). Research and design appropriate UI patterns (e.g., inline error messages for specific fields, tooltips for contextual help, guided wizard steps for dependency chains) to display these messages intuitively. Create wireframes/mockups and detailed design specifications.",
            "dependencies": [],
            "details": "Focus on clarity, actionability, and minimizing user frustration. Consider accessibility guidelines. The output should be a set of UI/UX design artifacts.",
            "status": "pending",
            "testStrategy": "Internal design review with product and UX leads to ensure alignment with user experience goals."
          },
          {
            "id": 2,
            "title": "Develop Reusable Frontend Components for Guidance Display",
            "description": "Implement the core, reusable UI components (e.g., `InlineErrorMessage`, `ContextualTooltip`, `GuidanceBanner`, `GuidedWizardStep`) based on the design specifications from Subtask 11.1. These components should be generic enough to display various types of validation messages and suggestions.",
            "dependencies": [
              "11.1"
            ],
            "details": "Use the chosen frontend framework (e.g., React, Vue, Angular). Ensure components are styled consistently with the application's design system and are highly reusable.",
            "status": "pending",
            "testStrategy": "Write unit tests for component rendering, prop handling, and state changes. Conduct visual regression tests to ensure consistent appearance."
          },
          {
            "id": 3,
            "title": "Integrate Configuration UI with Validation Endpoint (Task 9)",
            "description": "Implement the frontend logic to call the `/api/settings/validate` endpoint (Task 9) in real-time as users interact with configuration fields or attempt to save. This involves setting up API calls, handling loading states, and storing the validation results in the frontend state.",
            "dependencies": [],
            "details": "Implement debouncing for validation calls on input changes to optimize performance. Map backend validation responses (e.g., `isValid`, `errors`, `suggestions`) to frontend-consumable error structures. Ensure robust error handling for API failures.",
            "status": "pending",
            "testStrategy": "Write frontend integration tests to verify API calls are made correctly, responses are processed, and the frontend state is updated appropriately. Mock Task 9 responses to test various validation scenarios."
          },
          {
            "id": 4,
            "title": "Implement Contextual Message Rendering Logic",
            "description": "Develop the specific logic within the configuration forms and pages to consume the validation results obtained from Subtask 11.3 and dynamically render the appropriate guidance messages using the components from Subtask 11.2. Ensure messages are displayed contextually (e.g., next to the relevant input field, as a prominent banner for global issues, or as part of a guided wizard flow).",
            "dependencies": [
              "11.2",
              "11.3"
            ],
            "details": "Map specific error codes/types from Task 9's output to predefined message templates and component placements. Implement conditional rendering based on validation state and user interaction. Prioritize actionable messages.",
            "status": "pending",
            "testStrategy": "Conduct end-to-end UI tests to verify messages appear correctly for various valid, invalid, and partially configured states. Test different UI patterns (tooltip, inline, wizard step) and ensure messages are contextually relevant."
          },
          {
            "id": 5,
            "title": "Conduct UI/UX Review and User Acceptance Testing (UAT)",
            "description": "Perform a comprehensive internal UI/UX review of the implemented guidance system. Prepare and execute user acceptance testing (UAT) with target personas to gather feedback on clarity, helpfulness, and intuitiveness of the messages and guidance flow. Iterate on the UI and message content based on UAT results.",
            "dependencies": [
              "11.4"
            ],
            "details": "Define UAT scenarios covering all expected validation states (e.g., missing dependencies, invalid inputs, successful configuration). Collect qualitative and quantitative feedback. Document UAT findings and prioritize necessary refinements.",
            "status": "pending",
            "testStrategy": "Document UAT findings, create bug reports/enhancement requests based on feedback. Verify all identified issues are addressed and the guidance system meets user expectations for clarity and helpfulness."
          }
        ]
      },
      {
        "id": 12,
        "title": "Implement `/api/settings/reset` Endpoint",
        "description": "Create a FastAPI endpoint to completely reset a user's settings in the database.",
        "details": "This endpoint should delete or archive all `userSettings` records associated with a given `userId`. Implement appropriate security checks, such as requiring a POST request and robust user authentication/authorization to prevent unauthorized resets.",
        "testStrategy": "Write API integration tests to verify that settings are correctly removed/reset for a user. Test edge cases like attempting to reset non-existent settings or unauthorized attempts.",
        "priority": "high",
        "dependencies": [],
        "status": "cancelled",
        "subtasks": [
          {
            "id": 1,
            "title": "Set up `/api/settings/reset` FastAPI Endpoint Structure",
            "description": "Create the basic FastAPI route for `/api/settings/reset`, ensuring it accepts POST requests. Define the necessary request and response models.",
            "dependencies": [],
            "details": "Utilize FastAPI's `APIRouter` to define the POST endpoint. The endpoint should not require a request body, as the `userId` will be derived from the authentication context. Define a simple response model for success confirmation.",
            "status": "pending",
            "testStrategy": "Manually test endpoint accessibility and basic response structure using a tool like Postman or curl."
          },
          {
            "id": 2,
            "title": "Implement User Authentication and Authorization for Reset Endpoint",
            "description": "Integrate robust security checks to ensure only authenticated and authorized users can trigger a settings reset for their own `userId`.",
            "dependencies": [
              "12.1"
            ],
            "details": "Utilize FastAPI's dependency injection for authentication (e.g., JWT token validation) to extract the `userId` from the request. Implement authorization logic to verify that the authenticated user is permitted to reset settings for the identified `userId` (typically their own). Return 401 Unauthorized for unauthenticated attempts and 403 Forbidden for unauthorized access attempts (e.g., trying to reset another user's settings).",
            "status": "pending",
            "testStrategy": "Write unit/integration tests to verify correct handling of valid tokens, invalid tokens, missing tokens, and attempts to reset settings for a different user."
          },
          {
            "id": 3,
            "title": "Develop Database Logic for User Settings Reset",
            "description": "Write the database interaction logic to either delete all `userSettings` records associated with the authenticated `userId` or mark them as archived in the PostgreSQL database.",
            "dependencies": [
              "12.2"
            ],
            "details": "Connect to the PostgreSQL database using the established ORM (e.g., SQLAlchemy). Implement a `DELETE` operation on the `userSettings` table where the `userId` column matches the authenticated user's ID. Alternatively, if archiving is preferred, implement an `UPDATE` operation to set an `isArchived` flag or similar status. Ensure the operation is atomic.",
            "status": "pending",
            "testStrategy": "Write unit tests for the database interaction layer to ensure correct SQL queries are generated and executed for deletion/archiving. Mock the database connection for isolated testing."
          },
          {
            "id": 4,
            "title": "Implement API Responses and Error Handling for Reset Endpoint",
            "description": "Define appropriate HTTP responses for success and various error scenarios, such as no settings found for the user, database errors, or internal server errors.",
            "dependencies": [
              "12.3"
            ],
            "details": "Return a 200 OK response upon successful reset, possibly with a confirmation message. Handle cases where no settings were found for the user (e.g., still return 200 OK with a specific message, or 204 No Content if appropriate, as the 'reset' state is achieved). Implement `try-except` blocks around database operations to catch and handle potential exceptions, returning 500 Internal Server Error for unexpected database issues.",
            "status": "pending",
            "testStrategy": "Test the endpoint's responses for successful operations, cases where no settings exist to reset, and simulated database errors to ensure correct HTTP status codes and response bodies."
          },
          {
            "id": 5,
            "title": "Write Comprehensive Integration Tests for `/api/settings/reset`",
            "description": "Create automated API integration tests to verify the correct functionality, security, and error handling of the `/api/settings/reset` endpoint.",
            "dependencies": [
              "12.4"
            ],
            "details": "Use `pytest` and FastAPI's `TestClient` or `httpx`. Test cases should include: successful reset for an authenticated user with existing settings; successful reset for an authenticated user with no existing settings; unauthorized access attempts (e.g., missing token, invalid token, attempting to reset another user's settings); and verification that settings are indeed removed/archived from the database after a successful reset. Ensure tests cover edge cases as described in the parent task.",
            "status": "pending",
            "testStrategy": "Execute tests against a test database instance. Verify database state before and after endpoint calls. Use mock authentication for security tests."
          }
        ]
      },
      {
        "id": 13,
        "title": "Develop Full Settings Reset UI with Safety Confirmation",
        "description": "Implement a UI component that allows users to completely reset their settings, including a mandatory confirmation dialog to prevent accidental data loss.",
        "details": "Design a clear button/menu item for 'Reset All Settings'. The confirmation dialog should explicitly state the irreversible nature of the action and require user confirmation (e.g., typing 'RESET'). Integrate this UI with the `/api/settings/reset` endpoint.",
        "testStrategy": "Manually test the reset flow, including confirmation and cancellation. Use React Testing Library to ensure dialog behavior is correct and the API call is only made upon explicit confirmation.",
        "priority": "high",
        "dependencies": [
          8,
          12
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement 'Reset All Settings' UI Trigger",
            "description": "Create the visual button or menu item that initiates the settings reset process.",
            "dependencies": [],
            "details": "Design a clear, distinct button or menu item (e.g., in a settings page or profile dropdown) labeled 'Reset All Settings'. Ensure it's visually distinct and accessible.",
            "status": "pending",
            "testStrategy": "Unit tests to ensure the button renders correctly and triggers an event (e.g., `onClick`) when clicked."
          },
          {
            "id": 2,
            "title": "Develop Settings Reset Confirmation Dialog UI",
            "description": "Create the modal or dialog component that prompts the user for confirmation before resetting settings.",
            "dependencies": [
              "13.1"
            ],
            "details": "Design a modal dialog with a clear title (e.g., 'Confirm Settings Reset'), a warning message about irreversibility, and an input field where the user must type 'RESET' to confirm. Include 'Cancel' and 'Confirm' buttons.",
            "status": "pending",
            "testStrategy": "Snapshot tests for the dialog's appearance. React Testing Library tests to verify all elements (title, message, input, buttons) are present when the dialog is open."
          },
          {
            "id": 3,
            "title": "Implement Confirmation Dialog Logic and Input Validation",
            "description": "Add the frontend logic to control the visibility of the confirmation dialog, handle user input in the confirmation field, and enable/disable the confirm button based on input.",
            "dependencies": [
              "13.2"
            ],
            "details": "Implement state management for dialog visibility. Add an event handler for the input field to check if the typed text matches 'RESET' (case-sensitive). The 'Confirm' button should only become active when the input is correct. Handle 'Cancel' button logic to close the dialog.",
            "status": "pending",
            "testStrategy": "React Testing Library tests to simulate typing 'RESET' and verify the 'Confirm' button state. Test cancellation behavior."
          },
          {
            "id": 4,
            "title": "Integrate Settings Reset UI with Backend API",
            "description": "Implement the logic to make an API call to `/api/settings/reset` when the user confirms the reset action.",
            "dependencies": [
              "13.3"
            ],
            "details": "Upon successful confirmation (i.e., 'Confirm' button clicked and input validated), dispatch an asynchronous action to call the `/api/settings/reset` endpoint. Handle loading states during the API call.",
            "status": "pending",
            "testStrategy": "Use Jest mocks for `fetch` or `axios` to simulate API success and failure. Verify that the API call is made with the correct method (e.g., POST/DELETE) and only after explicit confirmation."
          },
          {
            "id": 5,
            "title": "Implement Post-Reset UI Updates and Error Handling",
            "description": "Manage the UI state after the API call, including displaying success/error messages and potentially redirecting or refreshing the settings.",
            "dependencies": [
              "13.4"
            ],
            "details": "After a successful API response, display a success notification (e.g., a toast message), close the dialog, and potentially trigger a re-fetch of settings or a page refresh to reflect the reset state. Implement robust error handling for API failures, displaying user-friendly error messages.",
            "status": "pending",
            "testStrategy": "React Testing Library tests to verify success/error messages are displayed correctly. Test that the dialog closes and the UI updates appropriately after a mocked successful API call. Test error message display on mocked API failure."
          }
        ]
      },
      {
        "id": 14,
        "title": "Enhance Backup/Restore UI & Implement Client-Side Versioning",
        "description": "Improve the existing backup/restore UI and add client-side logic for basic settings versioning to allow reverting to previous states.",
        "details": "For backup, allow users to download a JSON file of their current settings. For restore, allow uploading a JSON file to apply settings. Implement a simple client-side versioning mechanism (e.g., storing the last 3-5 versions of settings in LocalStorage or IndexedDB) to enable quick reverts.",
        "testStrategy": "Manually test backup (download) and restore (upload) functionalities with various valid and invalid JSON files. Write unit tests for the client-side versioning logic, ensuring versions are correctly stored and retrieved.",
        "priority": "medium",
        "dependencies": [
          8
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Backup UI and Settings Export",
            "description": "Develop the user interface elements (e.g., a 'Download Settings' button) and the client-side logic to gather the current application settings and prepare them for download as a JSON file.",
            "dependencies": [],
            "details": "Retrieve the current settings from the application's state/store, serialize them into a JSON string, and trigger a file download in the browser using Blob and URL.createObjectURL.\n<info added on 2025-08-21T19:27:04.337Z>\nIt has been confirmed that Task 14.1 is already completed. All requirements for Task 14.1 are already implemented, and no additional work is needed.\n\n**Existing Implementation Details:**\n*   A complete backup UI is implemented in the `ImportExportBox.jsx` component.\n*   The `usePreference.js` hook provides the `exportSettings` function.\n*   JSON file download functionality is fully operational.\n*   Supports both full and partial settings export.\n*   Custom file naming is possible.\n*   Individual selection export is available for 5 setting sections.\n*   Real-time status display and progress UI are included.\n\n**Implemented Core Features:**\n1.  Current settings are serialized into JSON.\n2.  File download is handled using Blob and URL.createObjectURL.\n3.  Timestamp-based automatic file naming is implemented.\n4.  Metadata (export time, version, etc.) is included.\n5.  Error handling and Toast notifications are provided.\n</info added on 2025-08-21T19:27:04.337Z>",
            "status": "done",
            "testStrategy": "Manually test the 'Download Settings' button to ensure a JSON file is downloaded with the correct current settings. Unit tests for the settings serialization logic."
          },
          {
            "id": 2,
            "title": "Implement Restore UI and Settings Import",
            "description": "Develop the user interface elements (e.g., an 'Upload Settings' button/input) and the client-side logic to allow users to select a JSON file, read its content, and perform initial parsing.",
            "dependencies": [],
            "details": "Create an input element of type 'file' that accepts JSON files. Use the FileReader API to read the content of the selected file and attempt to parse it as JSON. Handle basic file reading errors.",
            "status": "done",
            "testStrategy": "Manually test the file upload input with valid JSON files and invalid (non-JSON) files. Unit tests for file reading and initial JSON parsing logic, ensuring error handling for malformed JSON."
          },
          {
            "id": 3,
            "title": "Integrate Imported Settings and Basic Validation",
            "description": "Implement the logic to apply the settings parsed from the uploaded JSON file to the application's state. This includes basic structural validation to ensure the uploaded file contains expected settings keys before applying them.",
            "dependencies": [
              "14.2"
            ],
            "details": "After successfully parsing the JSON from the uploaded file, update the application's settings state. Add checks to ensure the uploaded JSON structure matches the expected settings schema (e.g., presence of key fields) to prevent application errors. Provide user feedback on success or validation failure.",
            "status": "done",
            "testStrategy": "Unit tests to verify that valid JSON settings are correctly applied to the application state. Test with malformed or incomplete JSON to ensure basic validation catches errors and provides appropriate user feedback."
          },
          {
            "id": 4,
            "title": "Develop Client-Side Settings Versioning Logic",
            "description": "Implement the core logic for storing multiple versions of user settings client-side (e.g., in LocalStorage or IndexedDB). This includes functions to save a new version, retrieve all stored versions, and manage the version history (e.g., keeping only the last 3-5 versions).",
            "dependencies": [],
            "details": "Choose LocalStorage or IndexedDB for storage. Implement functions like `saveSettingsVersion(settings)`, `getSettingsVersions()`, and `pruneOldVersions()`. Each saved version should include a timestamp and a unique identifier. Ensure the version limit (3-5) is enforced.",
            "status": "done",
            "testStrategy": "Unit tests to verify that versions are correctly saved, retrieved, and pruned according to the specified limit. Test edge cases like saving the first version, saving beyond the limit, and retrieving non-existent versions."
          },
          {
            "id": 5,
            "title": "Integrate Versioning UI and Revert Functionality",
            "description": "Enhance the UI to display available settings versions and provide a mechanism (e.g., a dropdown or list of versions with 'Revert' buttons) for users to select and apply a previous version of their settings.",
            "dependencies": [
              "14.3",
              "14.4"
            ],
            "details": "Use the functions developed in 14.4 to populate a UI component (e.g., a list or dropdown) with available settings versions. When a user selects a version to revert, retrieve that version's data and apply it to the application's settings state using the logic from 14.3. Ensure a new version is saved *after* a successful revert, as the reverted state becomes the new current state.",
            "status": "done",
            "testStrategy": "Manually test the version history display and the 'Revert' functionality for different versions. Unit tests for the logic that applies a selected historical version to the current settings. Ensure a new version is correctly saved after a revert operation."
          }
        ]
      },
      {
        "id": 15,
        "title": "Configure E2E Testing & CI/CD Integration",
        "description": "Set up Playwright for end-to-end testing of key user flows and integrate all new tests into the existing CI/CD pipeline.",
        "details": "Write comprehensive Playwright tests covering the core user flows: persistent settings (login, configure, re-login), order-independent configuration (PEG/Statistics setup), and settings management (backup, restore, reset). Update Dockerfiles and CI/CD scripts to automatically run these E2E tests on every code push.",
        "testStrategy": "Run full CI/CD pipeline to verify E2E tests pass. Monitor test results and coverage reports. Ensure tests are stable and reliable across different environments.",
        "priority": "high",
        "dependencies": [
          8,
          10,
          13
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Initialize Playwright Test Environment",
            "description": "Set up the Playwright testing framework in the project, including installation of necessary dependencies and creation of a basic sanity test.",
            "dependencies": [],
            "details": "Install Playwright, configure `playwright.config.ts` for browser setup (Chromium, Firefox, WebKit), and create a simple 'hello world' test (e.g., navigating to the homepage and asserting title) to confirm the setup is working.",
            "status": "pending",
            "testStrategy": "Run `npx playwright test` locally to ensure the basic test passes and browsers launch correctly."
          },
          {
            "id": 2,
            "title": "Develop E2E Tests for Persistent Settings Flow",
            "description": "Write comprehensive Playwright tests to cover the core user flow involving login, configuring settings, and verifying persistence after re-login.",
            "dependencies": [
              "15.1"
            ],
            "details": "Create Playwright test suites for: successful user login and authentication; navigating to user settings and making changes (e.g., preferences); logging out and then logging back in; and finally, verifying that the previously configured settings are correctly loaded and displayed upon re-login.",
            "status": "pending",
            "testStrategy": "Run these specific test suites locally using Playwright to ensure all assertions pass for the persistent settings flow."
          },
          {
            "id": 3,
            "title": "Develop E2E Tests for Configuration & Management Flows",
            "description": "Develop Playwright tests for the order-independent configuration of PEG/Statistics and the settings management features (backup, restore, reset).",
            "dependencies": [
              "15.1"
            ],
            "details": "Create Playwright test suites for: configuring PEG settings and verifying their dependencies/validation (leveraging Task 10/11 context); configuring Statistics settings and verifying their dependencies/validation; testing the ability to backup user settings; testing the ability to restore user settings from a backup; and testing the ability to reset user settings to default. Ensure tests cover various valid and invalid configuration scenarios.",
            "status": "pending",
            "testStrategy": "Run these specific test suites locally using Playwright to ensure all assertions pass for various configuration and management scenarios."
          },
          {
            "id": 4,
            "title": "Update Dockerfiles for Playwright Test Execution",
            "description": "Modify existing Dockerfiles to include all necessary dependencies for Playwright to run within the containerized environment.",
            "dependencies": [
              "15.2",
              "15.3"
            ],
            "details": "Add Playwright browser dependencies (e.g., `ms-playwright-browser-drivers` or system-level browser packages like Chromium, Firefox, WebKit) to the relevant Dockerfile(s). Ensure the test runner can be invoked within the container and has the necessary permissions and environment variables.",
            "status": "pending",
            "testStrategy": "Build the Docker image and run a simple Playwright test command inside the container to verify that Playwright can execute tests successfully within the containerized environment."
          },
          {
            "id": 5,
            "title": "Configure CI/CD Pipeline for E2E Test Automation",
            "description": "Update the CI/CD pipeline scripts to automatically trigger and run the Playwright E2E tests on every code push, and ensure results are reported.",
            "dependencies": [
              "15.4"
            ],
            "details": "Modify the CI/CD configuration (e.g., `.github/workflows/*.yml`, `.gitlab-ci.yml`, `Jenkinsfile`) to add a new stage or step for E2E testing. This step should build the Docker image (if not already done), run the Playwright tests within the container, and configure reporting mechanisms (e.g., JUnit XML, Playwright HTML report archiving) for visibility.",
            "status": "pending",
            "testStrategy": "Push a small code change to trigger the CI/CD pipeline. Verify that the E2E test stage runs, completes successfully, and reports results as expected. Monitor for stability and reliability across different CI/CD runs."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-08-21T17:53:09.230Z",
      "updated": "2025-08-21T19:25:44.012Z",
      "description": "Tasks for master context"
    }
  }
}